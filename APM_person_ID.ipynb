{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "Deo3LUp9xVDO",
        "0Gu9dGEAambW",
        "5w1bEV1Gavmr"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup (Clone Repo)"
      ],
      "metadata": {
        "id": "J6uHGfe0YCEr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup YOLO"
      ],
      "metadata": {
        "id": "0ufAOsBudPKK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics\n",
        "\n"
      ],
      "metadata": {
        "id": "PeOAo4M8YHT6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1725708e-c0ca-429a-fabd-c54e176fdd4e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.155-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.2.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.4.26)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.155-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m101.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.155 ultralytics-thop-2.0.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Following cloning instructions from the orginal repo for APM"
      ],
      "metadata": {
        "id": "76zv307ykM2B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQljvoFK88N1",
        "outputId": "5749971e-443d-4e3f-f3d4-80b645002bb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'APM-David-Copy'...\n",
            "remote: Enumerating objects: 242, done.\u001b[K\n",
            "remote: Counting objects: 100% (25/25), done.\u001b[K\n",
            "remote: Compressing objects: 100% (21/21), done.\u001b[K\n",
            "remote: Total 242 (delta 11), reused 9 (delta 4), pack-reused 217 (from 1)\u001b[K\n",
            "Receiving objects: 100% (242/242), 24.68 MiB | 15.54 MiB/s, done.\n",
            "Resolving deltas: 100% (109/109), done.\n",
            "/content/APM-David-Copy\n",
            "APM_person_ID.ipynb  interpolate.py\t    README.md\n",
            "assets\t\t     lawnmower_images.zip   single_token_segmentation\n",
            "david.jpeg\t     misc_scripts\t    visualize_coco.py\n",
            "download.sh\t     model.py\n",
            "flop_analysis\t     predict_test_image.py\n"
          ]
        }
      ],
      "source": [
        "#try to clone the APM-David-Copy repo\n",
        "%cd /content\n",
        "!git clone https://github.com/davidg335/APM-David-Copy.git\n",
        "%cd APM-David-Copy/\n",
        "! ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#make sure local is up to date with main branch\n",
        "!git pull origin main\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5MsJyQ4rgDV",
        "outputId": "a3edcbc8-6d59-4d0b-dde1-1e3cfaa47089"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From https://github.com/davidg335/APM-David-Copy\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hI2KOLJTR2KH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget \"https://www.cs.ucf.edu/~rmodi/apm/model_15.pth\"\n",
        "# !wget https://www.cs.ucf.edu/~rmodi/apm/data.zip\n",
        "!mkdir checkpoints\n",
        "!mv model_15.pth checkpoints/\n",
        "# !unzip data.zip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jddi1NqUjYZM",
        "outputId": "989a0a43-69b1-480a-afec-23840cc63a69"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-15 20:16:34--  https://www.cs.ucf.edu/~rmodi/apm/model_15.pth\n",
            "Resolving www.cs.ucf.edu (www.cs.ucf.edu)... 132.170.216.243\n",
            "Connecting to www.cs.ucf.edu (www.cs.ucf.edu)|132.170.216.243|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 217396607 (207M)\n",
            "Saving to: ‘model_15.pth’\n",
            "\n",
            "model_15.pth        100%[===================>] 207.33M  67.6MB/s    in 3.1s    \n",
            "\n",
            "2025-06-15 20:16:37 (67.6 MB/s) - ‘model_15.pth’ saved [217396607/217396607]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wWTGXwXeYROi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unzip testing/training images\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "T3ti2N4WkpUi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip lawnmower_images.zip -d lawnmower_images\n"
      ],
      "metadata": {
        "id": "9i3iUqkRgyyc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e1ef322-18c9-4f9a-a122-0196de86d090"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  lawnmower_images.zip\n",
            "   creating: lawnmower_images/lawnmower_images/\n",
            "   creating: lawnmower_images/lawnmower_images/test/\n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0001.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0002.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0003.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0004.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0005.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0006.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0007.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0008.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0009.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0010.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0011.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0012.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0013.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0014.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0015.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0016.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0017.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0018.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0019.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0020.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0021.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0022.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0023.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0024.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0025.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0026.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0027.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0028.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0029.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0030.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0031.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0032.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0033.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0034.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0035.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0036.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0037.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0038.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0039.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0040.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0041.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0042.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0043.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0044.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0045.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0046.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0047.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0048.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0049.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0050.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0051.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0052.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0053.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0054.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0055.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0056.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0057.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0058.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0059.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0060.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0061.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0062.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0063.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0064.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0065.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0066.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0067.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0068.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0069.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0070.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0071.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0072.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0073.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0074.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0075.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0076.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0077.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0078.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0079.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0080.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0081.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0082.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0083.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0084.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0085.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0086.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0087.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0088.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0089.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0090.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0091.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0092.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0093.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0094.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0095.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0096.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0097.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0098.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0099.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0100.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0101.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0102.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0103.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0104.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0105.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0106.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0107.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0108.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0109.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0110.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0111.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0112.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0113.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0114.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0115.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0116.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0117.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0118.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0119.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0120.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0121.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0122.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0123.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0124.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0125.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0126.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0127.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0128.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0129.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0130.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0131.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0132.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0133.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0134.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0135.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0136.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0137.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0138.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0139.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0140.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0141.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0142.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0143.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0144.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0145.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0146.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0147.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0148.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0149.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0150.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0199.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0200.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0201.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0202.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0203.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0204.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0205.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0206.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0207.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0208.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0209.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0210.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0211.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0212.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0213.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0214.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0215.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0216.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0217.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0218.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0219.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0220.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0221.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0222.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0223.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0224.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0225.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0226.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0227.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0228.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0229.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0230.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0231.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0232.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0233.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0234.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0235.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0236.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0237.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0238.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0239.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/test/frames_0240.jpg  \n",
            "   creating: lawnmower_images/lawnmower_images/train/\n",
            "  inflating: lawnmower_images/lawnmower_images/train/frames_0151.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/train/frames_0152.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/train/frames_0153.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/train/frames_0154.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/train/frames_0155.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/train/frames_0156.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/train/frames_0157.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/train/frames_0158.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/train/frames_0159.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/train/frames_0160.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/train/frames_0161.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/train/frames_0162.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/train/frames_0163.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/train/frames_0164.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/train/frames_0165.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/train/frames_0166.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/train/frames_0167.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/train/frames_0168.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/train/frames_0169.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/train/frames_0170.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/train/frames_0171.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/train/frames_0172.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/train/frames_0173.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/train/frames_0174.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/train/frames_0175.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/train/frames_0176.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/train/frames_0177.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/train/frames_0178.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/train/frames_0179.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/train/frames_0180.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/train/frames_0181.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/train/frames_0182.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/train/frames_0183.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/train/frames_0184.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/train/frames_0185.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/train/frames_0186.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/train/frames_0187.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/train/frames_0188.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/train/frames_0189.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/train/frames_0190.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/train/frames_0191.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/train/frames_0192.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/train/frames_0193.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/train/frames_0194.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/train/frames_0195.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/train/frames_0196.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/train/frames_0197.jpg  \n",
            "  inflating: lawnmower_images/lawnmower_images/train/frames_0198.jpg  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model accuracy"
      ],
      "metadata": {
        "id": "0Jr5DWHHYOMZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#model = Model().cuda()\n",
        "#x = torch.randn(4,3,448,448)\n",
        "#x_avg = torch.randn(4,3,32,32)\n",
        "#feat = torch.randn(4,1024,1024)\n",
        "#loss, feat_loss, rgb_loss, feat_out, rgb_out = model.forward_wrapper(x,x_avg, feat)\n",
        "#print(feat_loss, rgb_loss,feat_out.shape, rgb_out.shape)"
      ],
      "metadata": {
        "id": "N5kF9p03iqr9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# model.py\n",
        "\n"
      ],
      "metadata": {
        "id": "6hwEC8wXYT1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import glob\n",
        "from pathlib import Path\n",
        "import cv2\n",
        "from einops import rearrange, reduce, repeat\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "\n",
        "def positionalencoding2d(d_model, height, width):\n",
        "    \"\"\"\n",
        "    :param d_model: dimension of the model\n",
        "    :param height: height of the positions\n",
        "    :param width: width of the positions\n",
        "    :return: d_model*height*width position matrix\n",
        "    \"\"\"\n",
        "    if d_model % 4 != 0:\n",
        "        raise ValueError(\"Cannot use sin/cos positional encoding with \"\n",
        "                         \"odd dimension (got dim={:d})\".format(d_model))\n",
        "    pe = torch.zeros(d_model, height, width)\n",
        "    # Each dimension use half of d_model\n",
        "    d_model = int(d_model / 2)\n",
        "    div_term = torch.exp(torch.arange(0., d_model, 2) *\n",
        "                         -(math.log(10000.0) / d_model))\n",
        "    pos_w = torch.arange(0., width).unsqueeze(1)\n",
        "    pos_h = torch.arange(0., height).unsqueeze(1)\n",
        "    pe[0:d_model:2, :, :] = torch.sin(pos_w * div_term).transpose(0, 1).unsqueeze(1).repeat(1, height, 1)\n",
        "    pe[1:d_model:2, :, :] = torch.cos(pos_w * div_term).transpose(0, 1).unsqueeze(1).repeat(1, height, 1)\n",
        "    pe[d_model::2, :, :] = torch.sin(pos_h * div_term).transpose(0, 1).unsqueeze(2).repeat(1, 1, width)\n",
        "    pe[d_model + 1::2, :, :] = torch.cos(pos_h * div_term).transpose(0, 1).unsqueeze(2).repeat(1, 1, width)\n",
        "\n",
        "    return pe.cuda()\n",
        "\n",
        "\n",
        "class Model(nn.Module):\n",
        "    # h,w of the image which will be fwd pass.\n",
        "    # coordinate based query\n",
        "    def __init__(self, hidden_dim = 1024, h = 32, w = 32, fwd_chunk_size = 16):\n",
        "\n",
        "        super(Model, self).__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(2*hidden_dim, 4096)\n",
        "        self.fc2 = nn.Linear(4096,4096)\n",
        "        self.fc3 = nn.Linear(4096,4096)\n",
        "        self.fc4 = nn.Linear(4096, 2048)\n",
        "        self.fc5 = nn.Linear(2048,1024)\n",
        "\n",
        "        self.feat_proj_head = nn.Linear(1024, 1024)\n",
        "        self.rgb_head_1 = nn.Linear(hidden_dim*3, 256) #input is x position vector, \"DNA\" vector T, and feature vector output for that pixel feat (the output of the MLP)\n",
        "        self.rgb_head_2 = nn.Linear(256,256)\n",
        "        self.rgb_head_3 = nn.Linear(256,3)\n",
        "\n",
        "        #initialize positional encoding\n",
        "        self.pos = positionalencoding2d(hidden_dim, h,w) #to break input coordinate symmetry\n",
        "        self.h, self.w = h,w\n",
        "        self.fwd_chunk_size = fwd_chunk_size\n",
        "\n",
        "        #init a single patch size\n",
        "        #will operate on 448 by 448 to get information into the columns\n",
        "        self.patch_size = 14\n",
        "        self.stride = 14\n",
        "        self.conv1 = nn.Conv2d(3, 1, kernel_size=self.patch_size, stride=self.stride)\n",
        "\n",
        "    def forward_chunk(self, x):\n",
        "        x_pos = x#contains the whole cortical column stack\n",
        "\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc4(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc5(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        feat = self.feat_proj_head(x)\n",
        "\n",
        "        rgb = F.relu(self.rgb_head_1(torch.cat([feat,x_pos],1))) #breaks rgb output symmetry\n",
        "        rgb = F.relu(self.rgb_head_2(rgb))\n",
        "        rgb = F.relu(self.rgb_head_3(rgb))\n",
        "\n",
        "\n",
        "        return feat, rgb # feat is the feature which is produced\n",
        "\n",
        "    #x : b,c,h,w\n",
        "    # feat: b (h w) d\n",
        "\n",
        "    def forward_wrapper(self,x, x_avg, feat):\n",
        "        x,x_avg,feat = x.cuda(), x_avg.cuda(),feat.cuda() #moves the variables from the CPU to the GPU\n",
        "\n",
        "        b,c,h,w = x.shape #batch size (number of images), channel number (3 for RGB), height of image, width of image\n",
        "        feat = rearrange(feat, 'b (h w) d -> b d h w', h = self.h, w = self.w)\n",
        "\n",
        "        #trigger the copying of the average latent feature like dna\n",
        "        summary_feat = self.conv1(x)\n",
        "        summary_feat = rearrange(summary_feat, 'b c h w -> b (h w) c')#still need to resolve symmetry between locations in the cortical column\n",
        "        summary_feat = summary_feat.squeeze(-1)\n",
        "        summary_feat = repeat(summary_feat, 'b d -> b d h w', h = self.h, w = self.w) #squeezed the perceptual information into the column\n",
        "\n",
        "        # print(\"summary feat\", feat.shape, summary_feat.shape)\n",
        "\n",
        "        pos = self.pos  #d h w\n",
        "        pos = repeat(pos, 'd h w -> b d h w', b = b)\n",
        "\n",
        "        input_feat = torch.cat([summary_feat, pos], dim=1) #along d dimension, break identity symmetry at same input location\n",
        "\n",
        "        #batchify the entire forward pass\n",
        "        input_feat = rearrange(input_feat, 'b d h w -> (b h w) d')\n",
        "        target_feat = rearrange(feat, 'b d h w -> (b h w) d')\n",
        "        target_rgb = rearrange(x_avg, 'b c h w -> (b h w) c')\n",
        "\n",
        "        chunk_size = self.fwd_chunk_size\n",
        "        n_chunks = input_feat.shape[0] // chunk_size\n",
        "        if input_feat.shape[0] % chunk_size != 0:\n",
        "            n_chunks += 1\n",
        "        n_forwards = 0\n",
        "        for i in range(n_chunks):\n",
        "\n",
        "            start = i*chunk_size\n",
        "            end = min((i+1)*chunk_size, input_feat.shape[0])\n",
        "            input_feat_chunk = input_feat[start:end]\n",
        "\n",
        "            feat_chunk, rgb_chunk = self.forward_chunk(input_feat_chunk)\n",
        "\n",
        "            n_forwards+=1\n",
        "            if i == 0:\n",
        "                feat_out = feat_chunk\n",
        "                rgb_out = rgb_chunk\n",
        "            else:\n",
        "                feat_out = torch.cat([feat_out, feat_chunk], dim=0)\n",
        "                rgb_out = torch.cat([rgb_out, rgb_chunk], dim=0)\n",
        "\n",
        "        feat_loss = F.mse_loss(feat_out, target_feat)\n",
        "\n",
        "        rgb_loss = F.mse_loss(rgb_out, target_rgb)\n",
        "        loss = feat_loss + rgb_loss\n",
        "\n",
        "        rgb_out = rearrange(rgb_out, '(b h w) c -> b c h w', b = b, h = self.h, w = self.w)\n",
        "\n",
        "        return loss, feat_loss, rgb_loss, feat_out, rgb_out\n",
        "\n",
        "\n",
        "\n",
        "    # used for phasing one image into another. This is not needed for the NN architecture. It is a separate function.\n",
        "    def interpolate_function(self,x1,x2, n_interpolations = 100):\n",
        "        # no gradient flow required\n",
        "        with torch.no_grad():\n",
        "            x1,x2 = x1.cuda(), x2.cuda()\n",
        "            b,c,h,w = x1.shape\n",
        "\n",
        "            # f1,f2 are summary vectors\n",
        "            f1,f2 = self.conv1(x1), self.conv1(x2)\n",
        "            f1 = rearrange(f1,'b c h w -> b (h w) c')\n",
        "            f2 = rearrange(f2,'b c h w -> b (h w) c')\n",
        "            f1 = f1.squeeze(-1) #single col vector\n",
        "            f2 = f2.squeeze(-1) #single col vector\n",
        "\n",
        "            pos = self.pos  #d h w\n",
        "            pos = repeat(pos, 'd h w -> b d h w', b = b)\n",
        "\n",
        "            #generate n_interpolations between f1 and f2\n",
        "            interpolation_vectors = []\n",
        "            for i in range(n_interpolations):\n",
        "                interpolation_vectors.append(f1 + (f2 - f1) * i / n_interpolations)\n",
        "\n",
        "            output_feats = []\n",
        "            output_rgbs = []\n",
        "\n",
        "            for i in range(n_interpolations):\n",
        "                print(\"interpolation\", i, \"/\", n_interpolations)\n",
        "                summary_vector = interpolation_vectors[i]\n",
        "                print(\"interpolation shape\", summary_vector.shape)\n",
        "                summary_vector = repeat(summary_vector, 'b d -> b d h w', h = self.h, w = self.w) #repeat column vector to all locations\n",
        "                summary_vector = summary_vector.cuda()\n",
        "                input_feat = torch.cat([summary_vector, pos], dim=1) #along d dimension\n",
        "                #batchify the entire forward pass\n",
        "                input_feat = rearrange(input_feat, 'b d h w -> (b h w) d')\n",
        "\n",
        "                chunk_size = self.fwd_chunk_size\n",
        "                n_chunks = input_feat.shape[0] // chunk_size\n",
        "                if input_feat.shape[0] % chunk_size != 0:\n",
        "                    n_chunks += 1\n",
        "                for j in range(n_chunks):\n",
        "                    # print(\"chunk\", i, \"/\", n_chunks)\n",
        "                    start = j*chunk_size\n",
        "                    end = min((j+1)*chunk_size, input_feat.shape[0])\n",
        "                    input_feat_chunk = input_feat[start:end]\n",
        "                    feat_chunk, rgb_chunk = self.forward_chunk(input_feat_chunk)\n",
        "                    #rgb is not needed right now\n",
        "                    #rgb_out = None\n",
        "                    if j == 0:\n",
        "                        feat_out = feat_chunk\n",
        "                        rgb_out = rgb_chunk\n",
        "                    else:\n",
        "                        feat_out = torch.cat([feat_out, feat_chunk], dim=0)\n",
        "                        rgb_out = torch.cat([rgb_out, rgb_chunk], dim=0)\n",
        "\n",
        "                feat_out  = feat_out.cpu().detach().numpy()\n",
        "                output_feats.append(feat_out)\n",
        "                output_rgbs.append(rgb_out)\n",
        "                feat_out = None #next vector interpolation happens here\n",
        "                rgb_out = None\n",
        "\n",
        "        print(\"getting ready to return....\")\n",
        "        # exit(1)\n",
        "        return output_feats,output_rgbs\n",
        "\n",
        "    def predict_image(self, x):\n",
        "        x = x.cuda()\n",
        "        b,c,h,w = x.shape\n",
        "\n",
        "        summary_feat = self.conv1(x)\n",
        "        summary_feat = rearrange(summary_feat, 'b c h w -> b (h w) c')\n",
        "        summary_feat = summary_feat.squeeze(-1)\n",
        "        summary_feat = repeat(summary_feat, 'b d -> b d h w', h = self.h, w = self.w)\n",
        "\n",
        "        pos = self.pos\n",
        "        pos = repeat(pos, 'd h w -> b d h w', b = b)\n",
        "\n",
        "        input_feat = torch.cat([summary_feat, pos], dim=1)\n",
        "        input_feat = rearrange(input_feat, 'b d h w -> (b h w) d')\n",
        "\n",
        "        chunk_size = self.fwd_chunk_size\n",
        "        n_chunks = input_feat.shape[0] // chunk_size\n",
        "        if input_feat.shape[0] % chunk_size != 0:\n",
        "            n_chunks += 1\n",
        "        n_forwards =0\n",
        "        for i in range(n_chunks):\n",
        "            start = i*chunk_size\n",
        "            print(\"rmodi\", chunk_size, input_feat.shape[0], type(chunk_size), type(input_feat.shape[0]))\n",
        "\n",
        "            # end = min(int((i+1)*chunk_size), 1024)\n",
        "            end = min((i+1)*chunk_size, input_feat.shape[0])\n",
        "            input_feat_chunk = input_feat[start:end]\n",
        "            feat_chunk, rgb_chunk = self.forward_chunk(input_feat_chunk)\n",
        "\n",
        "            if i == 0:\n",
        "                feat_out = feat_chunk\n",
        "                rgb_out = rgb_chunk\n",
        "            else:\n",
        "                feat_out = torch.cat([feat_out, feat_chunk], dim=0)\n",
        "                rgb_out = torch.cat([rgb_out, rgb_chunk], dim=0)\n",
        "            n_forwards+=1\n",
        "        # print(\"no of forwards\", n_forwards)\n",
        "        # print(\"network just made 32*32 forward passes for 1024 pixels.  no need to keep all pixels of input percept in memory. A PATCH IS A BATCH. HAIL HINTON!!! HAIL GLOM!!!! :-)\")\n",
        "        # exit(1)\n",
        "        feat_out  = feat_out.cpu().detach().numpy()\n",
        "        rgb_out = rgb_out.cpu().detach().numpy()\n",
        "        return feat_out,rgb_out\n",
        "\n"
      ],
      "metadata": {
        "id": "NnKSoJ5J-OaE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# predict_test_image.py file\n",
        "\n",
        "Runs the model on a test image"
      ],
      "metadata": {
        "id": "Deo3LUp9xVDO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#predict_test_image.py file\n",
        "\n",
        "# author: rmodi\n",
        "# performs prediction on any test image\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "from pathlib import Path\n",
        "import cv2\n",
        "from einops import rearrange, reduce, repeat\n",
        "# from dataloader import PerceptionFieldDataset\n",
        "# from model import Model\n",
        "import copy\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "\n",
        "h,w = 32,32 # dimension of the input image into the folding block\n",
        "d = 1024 #size of the feature vector that will be attached to each pixel\n",
        "patch_size = 14\n",
        "fwd_chunk_size = 1\n",
        "batch_size = 1\n",
        "num_workers = 8\n",
        "num_epochs = 100000\n",
        "lr = 0.0001\n",
        "device = 'cuda'\n",
        "\n",
        "save_path = Path('./checkpoints')\n",
        "save_path.mkdir(parents=True, exist_ok=True)\n",
        "model_save_path = Path('checkpoints/model_15.pth')\n",
        "\n",
        "\n",
        "img_path = 'david.jpeg'\n",
        "img_name=img_path.split('.')[0]\n",
        "img = cv2.imread(img_path)\n",
        "print(\"read\")\n",
        "\n",
        "img = cv2.resize(img, (448,448))\n",
        "orig_img = copy.deepcopy(img)\n",
        "min_img = np.min(img)\n",
        "max = np.max(img)\n",
        "img = (img - min_img) / (max - min_img) #do min max scaling\n",
        "x = torch.from_numpy(img).permute(2,0,1).float()\n",
        "x = x.unsqueeze(0)\n",
        "x = x.to(device)\n",
        "print(\"x shape\", x.shape)\n",
        "########################################################################################\n",
        "#build model\n",
        "model = Model(hidden_dim = d, h = h, w = w, fwd_chunk_size = fwd_chunk_size).to(device)\n",
        "\n",
        "#load model\n",
        "model.load_state_dict(torch.load(model_save_path), strict = True)\n",
        "print(\"loaded model\")\n",
        "\n",
        "#perform prediction\n",
        "model.eval()\n",
        "\n",
        "#####################################################################################\n",
        "# exit(1)\n",
        "#recreating a test image using the model created\n",
        "with torch.no_grad(): # indicates that don't want weights to be updated via GD when testing\n",
        "    feat_out,rgb_out = model.predict_image(x) #rgb_out is reconstructed image 32x32x3, not sure what feat_out is, should be 1000x1000\n",
        "    print(\"feat out\", feat_out.shape)\n",
        "x = TSNE(n_components=3, #output has three dimensions\n",
        "         learning_rate='auto', #algorithm chooses learning rate\n",
        "              init='random', #embedding intialization is random\n",
        "          perplexity=3).fit_transform(feat_out) #perplexity is num nearest neighbors considered\n",
        "#x is the feature vector reduced to three dimensions (rgb)\n",
        "\n",
        "\n",
        "x = rearrange(x, '(h w) c -> h w c', h = 32, w = 32)\n",
        "\n",
        "#make x be normalized into rgb scale 0 to 255\n",
        "x = (x - np.min(x)) / (np.max(x) - np.min(x))\n",
        "x = x * 255\n",
        "x = x.astype(np.uint8)\n",
        "\n",
        "#making the output image black and white\n",
        "rgb_out = (rgb_out - np.min(rgb_out)) / (np.max(rgb_out) - np.min(rgb_out))\n",
        "rgb_out = rgb_out * 255\n",
        "rgb_out = rearrange(rgb_out, '(h w) c -> h w c', h = 32, w = 32)\n",
        "\n",
        "orig_img = cv2.resize(orig_img, (32,32)) #downsize image to fit input size 32x32 for model\n",
        "to_save =  np.concatenate((orig_img, rgb_out, x), axis = 1) #original image| predicted rgb| predicted feat.\n",
        "print(\"saving....\")\n",
        "cv2.imwrite('./viz_'+img_name+'.jpg', to_save) #save \"david.jpg\" input as three image output \"viz_david.jpg\" with original image, grayscale reconstruction, segmentation\n",
        "\n"
      ],
      "metadata": {
        "id": "mh0fN0tb-9Uh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15770772-a534-471e-a0cc-96a7dd857e13"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "read\n",
            "x shape torch.Size([1, 3, 448, 448])\n",
            "loaded model\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "rmodi 1 1024 <class 'int'> <class 'int'>\n",
            "feat out (1024, 1024)\n",
            "saving....\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "idtS4mwualj6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k4e7uUtGeAZY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# single token segmentation"
      ],
      "metadata": {
        "id": "O_UeTOtXae_Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model.py\n",
        "Definition of Model class (the APM model)"
      ],
      "metadata": {
        "id": "0Gu9dGEAambW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# i am forever humbled and grateful to geoff hinton for sharing his glom and forward forward paper with all of us.\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import glob\n",
        "from pathlib import Path\n",
        "import cv2\n",
        "from einops import rearrange, reduce, repeat\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "\n",
        "def positionalencoding2d(d_model, height, width):\n",
        "    \"\"\"\n",
        "    :param d_model: dimension of the model\n",
        "    :param height: height of the positions\n",
        "    :param width: width of the positions\n",
        "    :return: d_model*height*width position matrix\n",
        "    \"\"\"\n",
        "    if d_model % 4 != 0:\n",
        "        raise ValueError(\"Cannot use sin/cos positional encoding with \"\n",
        "                         \"odd dimension (got dim={:d})\".format(d_model))\n",
        "    pe = torch.zeros(d_model, height, width)\n",
        "    # Each dimension use half of d_model\n",
        "    d_model = int(d_model / 2)\n",
        "    div_term = torch.exp(torch.arange(0., d_model, 2) *\n",
        "                         -(math.log(10000.0) / d_model))\n",
        "    pos_w = torch.arange(0., width).unsqueeze(1)\n",
        "    pos_h = torch.arange(0., height).unsqueeze(1)\n",
        "    pe[0:d_model:2, :, :] = torch.sin(pos_w * div_term).transpose(0, 1).unsqueeze(1).repeat(1, height, 1)\n",
        "    pe[1:d_model:2, :, :] = torch.cos(pos_w * div_term).transpose(0, 1).unsqueeze(1).repeat(1, height, 1)\n",
        "    pe[d_model::2, :, :] = torch.sin(pos_h * div_term).transpose(0, 1).unsqueeze(2).repeat(1, 1, width)\n",
        "    pe[d_model + 1::2, :, :] = torch.cos(pos_h * div_term).transpose(0, 1).unsqueeze(2).repeat(1, 1, width)\n",
        "\n",
        "    return pe.cuda()\n",
        "\n",
        "\n",
        "class Model(nn.Module):\n",
        "    # h,w of the image which will be fwd pass.\n",
        "    # coordinate based query\n",
        "    def __init__(self, hidden_dim = 1024, h = 32, w = 32, fwd_chunk_size = 16):\n",
        "\n",
        "        super(Model, self).__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(2*hidden_dim, 4096)\n",
        "\n",
        "        self.fc4 = nn.Linear(4096, 2048)\n",
        "        self.fc5 = nn.Linear(2048,1024)\n",
        "\n",
        "        self.feat_proj_head = nn.Linear(1024, 768)\n",
        "        self.rgb_head_1 = nn.Linear(2816, 256)\n",
        "        self.rgb_head_2 = nn.Linear(256,256)\n",
        "        self.rgb_head_3 = nn.Linear(256,3)\n",
        "\n",
        "        #initialize positional encoding\n",
        "        self.pos = positionalencoding2d(hidden_dim, h,w) #to break input coordinate symmetry\n",
        "        self.h, self.w = h,w\n",
        "        self.fwd_chunk_size = fwd_chunk_size\n",
        "\n",
        "        #init a single patch size\n",
        "        #will operate on 448 by 448 to get information into the columns\n",
        "        self.patch_size = 14\n",
        "        self.stride = 14\n",
        "        self.conv1 = nn.Conv2d(3, 1, kernel_size=self.patch_size, stride=self.stride)\n",
        "        self.norm = nn.LayerNorm(hidden_dim)\n",
        "\n",
        "        self.little_self_attention = nn.MultiheadAttention(768, 8, batch_first=True)\n",
        "        self.little_query = nn.Parameter(torch.randn(768))\n",
        "        self.pos_output = positionalencoding2d(768, h,w) #loving attention at the output of the cortical stack.\n",
        "\n",
        "\n",
        "    def forward_chunk(self, x):\n",
        "\n",
        "        # print(\"slimmed down net..\")\n",
        "        x_pos = x#contains the whole cortical column stack\n",
        "\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = self.fc4(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc5(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        feat = self.feat_proj_head(x)\n",
        "\n",
        "        rgb = F.relu(self.rgb_head_1(torch.cat([feat,x_pos],1))) #breaks rgb output symmetry\n",
        "        rgb = F.relu(self.rgb_head_2(rgb))\n",
        "        rgb = F.relu(self.rgb_head_3(rgb))\n",
        "\n",
        "\n",
        "\n",
        "        return feat, rgb # feat is the feature which is produced\n",
        "\n",
        "    #x : b,c,h,w\n",
        "    # feat: b (h w) d\n",
        "\n",
        "    def forward_wrapper(self,x, x_avg, feat):\n",
        "        x,x_avg,feat = x.cuda(), x_avg.cuda(),feat.cuda()\n",
        "\n",
        "        b,c,h,w = x.shape\n",
        "\n",
        "        #trigger the copying of the average latent feature like dna\n",
        "        summary_feat = self.conv1(x)\n",
        "        summary_feat = rearrange(summary_feat, 'b c h w -> b (h w) c')#still need to resolve symmetry between locations in the cortical column\n",
        "        summary_feat = summary_feat.squeeze(-1)\n",
        "        summary_feat = repeat(summary_feat, 'b d -> b d h w', h = self.h, w = self.w) #squeezed the perceptual information into the column\n",
        "\n",
        "\n",
        "\n",
        "        pos = self.pos  #d h w\n",
        "        pos = repeat(pos, 'd h w -> b d h w', b = b)\n",
        "\n",
        "        input_feat = torch.cat([summary_feat, pos], dim=1) #along d dimension, break identity symmetry at same input location\n",
        "\n",
        "        #batchify the entire forward pass\n",
        "        input_feat = rearrange(input_feat, 'b d h w -> (b h w) d')\n",
        "\n",
        "        target_feat= feat\n",
        "        target_rgb = rearrange(x_avg, 'b c h w -> (b h w) c')\n",
        "\n",
        "        chunk_size = self.fwd_chunk_size\n",
        "        n_chunks = input_feat.shape[0] // chunk_size\n",
        "        if input_feat.shape[0] % chunk_size != 0:\n",
        "            n_chunks += 1\n",
        "        n_forwards = 0\n",
        "        for i in range(n_chunks):\n",
        "\n",
        "            start = i*chunk_size\n",
        "            end = min((i+1)*chunk_size, input_feat.shape[0])\n",
        "            input_feat_chunk = input_feat[start:end]\n",
        "\n",
        "            feat_chunk, rgb_chunk = self.forward_chunk(input_feat_chunk)\n",
        "\n",
        "            n_forwards+=1\n",
        "            if i == 0:\n",
        "                feat_out = feat_chunk\n",
        "                rgb_out = rgb_chunk\n",
        "            else:\n",
        "                feat_out = torch.cat([feat_out, feat_chunk], dim=0)\n",
        "                rgb_out = torch.cat([rgb_out, rgb_chunk], dim=0)\n",
        "\n",
        "\n",
        "        feat_out = rearrange(feat_out, '(b h w) d -> b h w d', b = b, h = self.h, w = self.w)\n",
        "        orig_feat_out = feat_out\n",
        "\n",
        "\n",
        "        pos_out = repeat(self.pos_output, 'd h w -> b d h w', b = b)\n",
        "        pos_out = rearrange(pos_out, 'b d h w -> b h w d')\n",
        "        feat_out = feat_out + pos_out\n",
        "        feat_out = rearrange(feat_out ,'b h w d -> b (h w) d')#(N,L,E q ​ ) when batch_first=True\n",
        "\n",
        "        query = repeat(self.little_query, 'd -> b  d', b = b, )\n",
        "        query = query.unsqueeze(1) #need one query only\n",
        "\n",
        "\n",
        "        feat_out, _ = self.little_self_attention(query, feat_out, feat_out)\n",
        "\n",
        "        feat_out = feat_out.squeeze(1)\n",
        "\n",
        "        feat_loss = F.mse_loss(feat_out, target_feat)\n",
        "        rgb_loss = 0\n",
        "\n",
        "        loss = feat_loss + rgb_loss\n",
        "\n",
        "        rgb_out = rearrange(rgb_out, '(b h w) c -> b c h w', b = b, h = self.h, w = self.w)\n",
        "\n",
        "        return loss, feat_loss, rgb_loss, feat_out, rgb_out,orig_feat_out\n",
        "\n"
      ],
      "metadata": {
        "id": "Z9t8gK5Ta8wy"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model_tta.py\n",
        "\n",
        "This code runs the train and test code through YOLO and outputs the labels and feature vectors for the train and test code."
      ],
      "metadata": {
        "id": "O87vmAkWaq54"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Set up transform (resize and convert to tensor)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((640, 640)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Custom dataset to load images from a folder\n",
        "class ImageFolderDataset(Dataset):\n",
        "    def __init__(self, folder_path, transform=None):\n",
        "        self.folder_path = folder_path\n",
        "        self.transform = transform\n",
        "        self.image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "        self.image_files.sort()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.folder_path, self.image_files[idx])\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, self.image_files[idx]  # return filename too for reference\n",
        "\n",
        "# Wrapper model that uses YOLO for inference\n",
        "#base class is torch.nn.Module\n",
        "class ModelTTA(torch.nn.Module):\n",
        "    def __init__(self, model_path='yolov5s.pt', device='cuda'):\n",
        "        super(ModelTTA, self).__init__()\n",
        "        print(\"Loading YOLO model...\")\n",
        "        self.device = device\n",
        "        self.model = YOLO(model_path)\n",
        "        print(\"YOLO loaded.\")\n",
        "\n",
        "    def forward(self, img):\n",
        "        # Undo ToTensor transform: convert tensor to numpy array for YOLO\n",
        "        img_np = img.mul(255).byte().permute(1, 2, 0).cpu().numpy()\n",
        "        results = self.model(img_np)\n",
        "        return results\n",
        "\n",
        "# Run inference on a dataset\n",
        "def run_inference_on_folder(folder_path, model):\n",
        "    dataset = ImageFolderDataset(folder_path, transform=transform)\n",
        "    dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "    for idx, (img, filename) in enumerate(dataloader):\n",
        "        print(f\"Processing {filename[0]} ({idx+1}/{len(dataset)})\")\n",
        "        img = img[0].to('cuda')  # remove batch dimension\n",
        "\n",
        "        results = model(img)\n",
        "\n",
        "        for res in results:\n",
        "            boxes = res.boxes\n",
        "            if boxes is not None and len(boxes) > 0:\n",
        "                for box in boxes:\n",
        "                    cls_id = int(box.cls[0])\n",
        "                    conf = float(box.conf[0])\n",
        "                    print(f\"Detected class {model.model.names[cls_id]} with confidence {conf:.3f}\")\n",
        "            else:\n",
        "                print(\"No detections\")\n",
        "        print(\"-----\")\n",
        "\n",
        "# this script here will only run when this script is run directly and not when it is imported as a module into another scipt\n",
        "# if this script is run directly, __name__ is automatically set to '__main__'\n",
        "if __name__ == '__main__':\n",
        "    model = ModelTTA().to('cuda')\n",
        "\n",
        "    # Set your paths here\n",
        "    train_path = '/content/APM-David-Copy/lawnmower_images/lawnmower_images/train'\n",
        "    test_path = '/content/APM-David-Copy/lawnmower_images/lawnmower_images/test'\n",
        "\n",
        "    print(\"Running on TRAIN set:\")\n",
        "    run_inference_on_folder(train_path, model)\n",
        "\n",
        "    print(\"Running on TEST set:\")\n",
        "    run_inference_on_folder(test_path, model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2jLi56ta4zt",
        "outputId": "2d938019-929c-4fb3-a408-dd2107520134",
        "collapsed": true
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "Loading YOLO model...\n",
            "PRO TIP 💡 Replace 'model=yolov5s.pt' with new 'model=yolov5su.pt'.\n",
            "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
            "\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov5su.pt to 'yolov5su.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 17.7M/17.7M [00:00<00:00, 135MB/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOLO loaded.\n",
            "Running on TRAIN set:\n",
            "Processing frames_0151.jpg (1/48)\n",
            "\n",
            "0: 640x640 1 person, 15.0ms\n",
            "Speed: 12.4ms preprocess, 15.0ms inference, 334.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.788\n",
            "-----\n",
            "Processing frames_0152.jpg (2/48)\n",
            "\n",
            "0: 640x640 1 person, 15.0ms\n",
            "Speed: 5.5ms preprocess, 15.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.840\n",
            "-----\n",
            "Processing frames_0153.jpg (3/48)\n",
            "\n",
            "0: 640x640 1 person, 14.9ms\n",
            "Speed: 4.9ms preprocess, 14.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.762\n",
            "-----\n",
            "Processing frames_0154.jpg (4/48)\n",
            "\n",
            "0: 640x640 1 person, 15.0ms\n",
            "Speed: 5.3ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.733\n",
            "-----\n",
            "Processing frames_0155.jpg (5/48)\n",
            "\n",
            "0: 640x640 1 person, 14.9ms\n",
            "Speed: 5.4ms preprocess, 14.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.834\n",
            "-----\n",
            "Processing frames_0156.jpg (6/48)\n",
            "\n",
            "0: 640x640 1 person, 14.9ms\n",
            "Speed: 5.3ms preprocess, 14.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.790\n",
            "-----\n",
            "Processing frames_0157.jpg (7/48)\n",
            "\n",
            "0: 640x640 1 person, 14.9ms\n",
            "Speed: 5.2ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.823\n",
            "-----\n",
            "Processing frames_0158.jpg (8/48)\n",
            "\n",
            "0: 640x640 1 person, 15.0ms\n",
            "Speed: 6.0ms preprocess, 15.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.614\n",
            "-----\n",
            "Processing frames_0159.jpg (9/48)\n",
            "\n",
            "0: 640x640 1 person, 15.0ms\n",
            "Speed: 7.3ms preprocess, 15.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.541\n",
            "-----\n",
            "Processing frames_0160.jpg (10/48)\n",
            "\n",
            "0: 640x640 1 person, 14.9ms\n",
            "Speed: 5.2ms preprocess, 14.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.410\n",
            "-----\n",
            "Processing frames_0161.jpg (11/48)\n",
            "\n",
            "0: 640x640 (no detections), 15.0ms\n",
            "Speed: 5.3ms preprocess, 15.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0162.jpg (12/48)\n",
            "\n",
            "0: 640x640 (no detections), 15.0ms\n",
            "Speed: 5.5ms preprocess, 15.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0163.jpg (13/48)\n",
            "\n",
            "0: 640x640 (no detections), 15.0ms\n",
            "Speed: 5.3ms preprocess, 15.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0164.jpg (14/48)\n",
            "\n",
            "0: 640x640 1 person, 15.0ms\n",
            "Speed: 4.4ms preprocess, 15.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.421\n",
            "-----\n",
            "Processing frames_0165.jpg (15/48)\n",
            "\n",
            "0: 640x640 (no detections), 14.9ms\n",
            "Speed: 6.2ms preprocess, 14.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0166.jpg (16/48)\n",
            "\n",
            "0: 640x640 (no detections), 14.9ms\n",
            "Speed: 5.3ms preprocess, 14.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0167.jpg (17/48)\n",
            "\n",
            "0: 640x640 (no detections), 15.0ms\n",
            "Speed: 5.3ms preprocess, 15.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0168.jpg (18/48)\n",
            "\n",
            "0: 640x640 (no detections), 14.9ms\n",
            "Speed: 5.3ms preprocess, 14.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0169.jpg (19/48)\n",
            "\n",
            "0: 640x640 (no detections), 14.9ms\n",
            "Speed: 5.2ms preprocess, 14.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0170.jpg (20/48)\n",
            "\n",
            "0: 640x640 (no detections), 15.0ms\n",
            "Speed: 7.1ms preprocess, 15.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0171.jpg (21/48)\n",
            "\n",
            "0: 640x640 (no detections), 14.9ms\n",
            "Speed: 5.0ms preprocess, 14.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0172.jpg (22/48)\n",
            "\n",
            "0: 640x640 (no detections), 15.0ms\n",
            "Speed: 5.1ms preprocess, 15.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0173.jpg (23/48)\n",
            "\n",
            "0: 640x640 (no detections), 14.7ms\n",
            "Speed: 4.9ms preprocess, 14.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0174.jpg (24/48)\n",
            "\n",
            "0: 640x640 (no detections), 14.6ms\n",
            "Speed: 5.2ms preprocess, 14.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0175.jpg (25/48)\n",
            "\n",
            "0: 640x640 (no detections), 14.7ms\n",
            "Speed: 5.3ms preprocess, 14.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0176.jpg (26/48)\n",
            "\n",
            "0: 640x640 (no detections), 14.6ms\n",
            "Speed: 5.6ms preprocess, 14.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0177.jpg (27/48)\n",
            "\n",
            "0: 640x640 (no detections), 14.6ms\n",
            "Speed: 5.5ms preprocess, 14.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0178.jpg (28/48)\n",
            "\n",
            "0: 640x640 (no detections), 14.6ms\n",
            "Speed: 5.3ms preprocess, 14.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0179.jpg (29/48)\n",
            "\n",
            "0: 640x640 (no detections), 14.6ms\n",
            "Speed: 5.1ms preprocess, 14.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0180.jpg (30/48)\n",
            "\n",
            "0: 640x640 (no detections), 14.7ms\n",
            "Speed: 5.4ms preprocess, 14.7ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0181.jpg (31/48)\n",
            "\n",
            "0: 640x640 (no detections), 14.6ms\n",
            "Speed: 5.3ms preprocess, 14.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0182.jpg (32/48)\n",
            "\n",
            "0: 640x640 (no detections), 14.7ms\n",
            "Speed: 6.6ms preprocess, 14.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0183.jpg (33/48)\n",
            "\n",
            "0: 640x640 (no detections), 14.8ms\n",
            "Speed: 6.2ms preprocess, 14.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0184.jpg (34/48)\n",
            "\n",
            "0: 640x640 (no detections), 14.7ms\n",
            "Speed: 6.2ms preprocess, 14.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0185.jpg (35/48)\n",
            "\n",
            "0: 640x640 (no detections), 14.8ms\n",
            "Speed: 9.3ms preprocess, 14.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0186.jpg (36/48)\n",
            "\n",
            "0: 640x640 (no detections), 14.6ms\n",
            "Speed: 5.6ms preprocess, 14.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0187.jpg (37/48)\n",
            "\n",
            "0: 640x640 (no detections), 14.6ms\n",
            "Speed: 5.5ms preprocess, 14.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0188.jpg (38/48)\n",
            "\n",
            "0: 640x640 (no detections), 14.6ms\n",
            "Speed: 5.5ms preprocess, 14.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0189.jpg (39/48)\n",
            "\n",
            "0: 640x640 (no detections), 14.7ms\n",
            "Speed: 6.1ms preprocess, 14.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0190.jpg (40/48)\n",
            "\n",
            "0: 640x640 (no detections), 14.6ms\n",
            "Speed: 8.8ms preprocess, 14.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0191.jpg (41/48)\n",
            "\n",
            "0: 640x640 (no detections), 14.6ms\n",
            "Speed: 4.9ms preprocess, 14.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0192.jpg (42/48)\n",
            "\n",
            "0: 640x640 (no detections), 14.6ms\n",
            "Speed: 5.1ms preprocess, 14.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0193.jpg (43/48)\n",
            "\n",
            "0: 640x640 (no detections), 14.6ms\n",
            "Speed: 5.2ms preprocess, 14.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0194.jpg (44/48)\n",
            "\n",
            "0: 640x640 (no detections), 14.6ms\n",
            "Speed: 5.2ms preprocess, 14.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0195.jpg (45/48)\n",
            "\n",
            "0: 640x640 (no detections), 14.7ms\n",
            "Speed: 6.8ms preprocess, 14.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0196.jpg (46/48)\n",
            "\n",
            "0: 640x640 (no detections), 14.7ms\n",
            "Speed: 7.9ms preprocess, 14.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0197.jpg (47/48)\n",
            "\n",
            "0: 640x640 (no detections), 14.7ms\n",
            "Speed: 7.5ms preprocess, 14.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0198.jpg (48/48)\n",
            "\n",
            "0: 640x640 (no detections), 18.6ms\n",
            "Speed: 7.1ms preprocess, 18.6ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Running on TEST set:\n",
            "Processing frames_0001.jpg (1/192)\n",
            "\n",
            "0: 640x640 1 person, 1 boat, 14.8ms\n",
            "Speed: 10.5ms preprocess, 14.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.787\n",
            "Detected class boat with confidence 0.292\n",
            "-----\n",
            "Processing frames_0002.jpg (2/192)\n",
            "\n",
            "0: 640x640 1 person, 15.8ms\n",
            "Speed: 7.3ms preprocess, 15.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.670\n",
            "-----\n",
            "Processing frames_0003.jpg (3/192)\n",
            "\n",
            "0: 640x640 1 person, 16.1ms\n",
            "Speed: 7.4ms preprocess, 16.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.791\n",
            "-----\n",
            "Processing frames_0004.jpg (4/192)\n",
            "\n",
            "0: 640x640 1 person, 16.4ms\n",
            "Speed: 7.3ms preprocess, 16.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.836\n",
            "-----\n",
            "Processing frames_0005.jpg (5/192)\n",
            "\n",
            "0: 640x640 2 persons, 14.7ms\n",
            "Speed: 8.0ms preprocess, 14.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.851\n",
            "Detected class person with confidence 0.284\n",
            "-----\n",
            "Processing frames_0006.jpg (6/192)\n",
            "\n",
            "0: 640x640 1 person, 14.7ms\n",
            "Speed: 7.1ms preprocess, 14.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.838\n",
            "-----\n",
            "Processing frames_0007.jpg (7/192)\n",
            "\n",
            "0: 640x640 1 person, 14.7ms\n",
            "Speed: 7.4ms preprocess, 14.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.783\n",
            "-----\n",
            "Processing frames_0008.jpg (8/192)\n",
            "\n",
            "0: 640x640 1 person, 14.7ms\n",
            "Speed: 7.5ms preprocess, 14.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.464\n",
            "-----\n",
            "Processing frames_0009.jpg (9/192)\n",
            "\n",
            "0: 640x640 1 person, 14.7ms\n",
            "Speed: 7.7ms preprocess, 14.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.782\n",
            "-----\n",
            "Processing frames_0010.jpg (10/192)\n",
            "\n",
            "0: 640x640 1 person, 14.7ms\n",
            "Speed: 7.6ms preprocess, 14.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.837\n",
            "-----\n",
            "Processing frames_0011.jpg (11/192)\n",
            "\n",
            "0: 640x640 1 person, 14.7ms\n",
            "Speed: 8.4ms preprocess, 14.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.861\n",
            "-----\n",
            "Processing frames_0012.jpg (12/192)\n",
            "\n",
            "0: 640x640 1 person, 14.7ms\n",
            "Speed: 7.5ms preprocess, 14.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.870\n",
            "-----\n",
            "Processing frames_0013.jpg (13/192)\n",
            "\n",
            "0: 640x640 1 person, 14.7ms\n",
            "Speed: 7.5ms preprocess, 14.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.861\n",
            "-----\n",
            "Processing frames_0014.jpg (14/192)\n",
            "\n",
            "0: 640x640 1 person, 14.7ms\n",
            "Speed: 7.4ms preprocess, 14.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.899\n",
            "-----\n",
            "Processing frames_0015.jpg (15/192)\n",
            "\n",
            "0: 640x640 1 person, 15.0ms\n",
            "Speed: 7.5ms preprocess, 15.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.846\n",
            "-----\n",
            "Processing frames_0016.jpg (16/192)\n",
            "\n",
            "0: 640x640 1 person, 15.0ms\n",
            "Speed: 7.7ms preprocess, 15.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.833\n",
            "-----\n",
            "Processing frames_0017.jpg (17/192)\n",
            "\n",
            "0: 640x640 1 person, 15.1ms\n",
            "Speed: 7.5ms preprocess, 15.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.843\n",
            "-----\n",
            "Processing frames_0018.jpg (18/192)\n",
            "\n",
            "0: 640x640 1 person, 15.0ms\n",
            "Speed: 7.7ms preprocess, 15.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.875\n",
            "-----\n",
            "Processing frames_0019.jpg (19/192)\n",
            "\n",
            "0: 640x640 1 person, 1 dog, 15.0ms\n",
            "Speed: 7.2ms preprocess, 15.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.862\n",
            "Detected class dog with confidence 0.307\n",
            "-----\n",
            "Processing frames_0020.jpg (20/192)\n",
            "\n",
            "0: 640x640 1 person, 1 dog, 15.0ms\n",
            "Speed: 7.2ms preprocess, 15.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.844\n",
            "Detected class dog with confidence 0.345\n",
            "-----\n",
            "Processing frames_0021.jpg (21/192)\n",
            "\n",
            "0: 640x640 1 person, 1 boat, 1 dog, 15.0ms\n",
            "Speed: 7.6ms preprocess, 15.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.837\n",
            "Detected class dog with confidence 0.370\n",
            "Detected class boat with confidence 0.283\n",
            "-----\n",
            "Processing frames_0022.jpg (22/192)\n",
            "\n",
            "0: 640x640 1 person, 1 boat, 1 dog, 18.2ms\n",
            "Speed: 7.3ms preprocess, 18.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.832\n",
            "Detected class boat with confidence 0.266\n",
            "Detected class dog with confidence 0.253\n",
            "-----\n",
            "Processing frames_0023.jpg (23/192)\n",
            "\n",
            "0: 640x640 1 person, 1 boat, 15.0ms\n",
            "Speed: 8.1ms preprocess, 15.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.866\n",
            "Detected class boat with confidence 0.271\n",
            "-----\n",
            "Processing frames_0024.jpg (24/192)\n",
            "\n",
            "0: 640x640 1 person, 1 boat, 15.0ms\n",
            "Speed: 7.2ms preprocess, 15.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.808\n",
            "Detected class boat with confidence 0.288\n",
            "-----\n",
            "Processing frames_0025.jpg (25/192)\n",
            "\n",
            "0: 640x640 1 person, 1 boat, 15.0ms\n",
            "Speed: 7.2ms preprocess, 15.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.851\n",
            "Detected class boat with confidence 0.288\n",
            "-----\n",
            "Processing frames_0026.jpg (26/192)\n",
            "\n",
            "0: 640x640 1 person, 1 boat, 15.0ms\n",
            "Speed: 8.6ms preprocess, 15.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.859\n",
            "Detected class boat with confidence 0.253\n",
            "-----\n",
            "Processing frames_0027.jpg (27/192)\n",
            "\n",
            "0: 640x640 1 person, 1 boat, 15.3ms\n",
            "Speed: 7.2ms preprocess, 15.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.868\n",
            "Detected class boat with confidence 0.258\n",
            "-----\n",
            "Processing frames_0028.jpg (28/192)\n",
            "\n",
            "0: 640x640 1 person, 1 boat, 16.3ms\n",
            "Speed: 10.5ms preprocess, 16.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.820\n",
            "Detected class boat with confidence 0.302\n",
            "-----\n",
            "Processing frames_0029.jpg (29/192)\n",
            "\n",
            "0: 640x640 1 person, 1 boat, 18.1ms\n",
            "Speed: 8.5ms preprocess, 18.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.833\n",
            "Detected class boat with confidence 0.281\n",
            "-----\n",
            "Processing frames_0030.jpg (30/192)\n",
            "\n",
            "0: 640x640 1 person, 1 boat, 15.0ms\n",
            "Speed: 10.4ms preprocess, 15.0ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.775\n",
            "Detected class boat with confidence 0.315\n",
            "-----\n",
            "Processing frames_0031.jpg (31/192)\n",
            "\n",
            "0: 640x640 1 person, 1 boat, 15.0ms\n",
            "Speed: 8.6ms preprocess, 15.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.551\n",
            "Detected class boat with confidence 0.369\n",
            "-----\n",
            "Processing frames_0032.jpg (32/192)\n",
            "\n",
            "0: 640x640 1 person, 1 boat, 15.0ms\n",
            "Speed: 8.2ms preprocess, 15.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.522\n",
            "Detected class boat with confidence 0.399\n",
            "-----\n",
            "Processing frames_0033.jpg (33/192)\n",
            "\n",
            "0: 640x640 1 boat, 15.0ms\n",
            "Speed: 7.4ms preprocess, 15.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class boat with confidence 0.361\n",
            "-----\n",
            "Processing frames_0034.jpg (34/192)\n",
            "\n",
            "0: 640x640 1 person, 1 boat, 15.0ms\n",
            "Speed: 7.1ms preprocess, 15.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.780\n",
            "Detected class boat with confidence 0.333\n",
            "-----\n",
            "Processing frames_0035.jpg (35/192)\n",
            "\n",
            "0: 640x640 1 person, 1 boat, 15.3ms\n",
            "Speed: 7.3ms preprocess, 15.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.760\n",
            "Detected class boat with confidence 0.321\n",
            "-----\n",
            "Processing frames_0036.jpg (36/192)\n",
            "\n",
            "0: 640x640 1 person, 1 car, 1 boat, 1 dog, 15.0ms\n",
            "Speed: 7.2ms preprocess, 15.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.824\n",
            "Detected class dog with confidence 0.582\n",
            "Detected class car with confidence 0.556\n",
            "Detected class boat with confidence 0.383\n",
            "-----\n",
            "Processing frames_0037.jpg (37/192)\n",
            "\n",
            "0: 640x640 1 person, 1 car, 1 boat, 15.4ms\n",
            "Speed: 7.7ms preprocess, 15.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.758\n",
            "Detected class car with confidence 0.732\n",
            "Detected class boat with confidence 0.426\n",
            "-----\n",
            "Processing frames_0038.jpg (38/192)\n",
            "\n",
            "0: 640x640 1 person, 1 car, 1 boat, 15.0ms\n",
            "Speed: 7.3ms preprocess, 15.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.810\n",
            "Detected class car with confidence 0.716\n",
            "Detected class boat with confidence 0.434\n",
            "-----\n",
            "Processing frames_0039.jpg (39/192)\n",
            "\n",
            "0: 640x640 1 person, 1 car, 1 boat, 15.4ms\n",
            "Speed: 7.6ms preprocess, 15.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.745\n",
            "Detected class car with confidence 0.716\n",
            "Detected class boat with confidence 0.416\n",
            "-----\n",
            "Processing frames_0040.jpg (40/192)\n",
            "\n",
            "0: 640x640 1 person, 1 car, 1 boat, 16.5ms\n",
            "Speed: 7.5ms preprocess, 16.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class car with confidence 0.760\n",
            "Detected class person with confidence 0.510\n",
            "Detected class boat with confidence 0.316\n",
            "-----\n",
            "Processing frames_0041.jpg (41/192)\n",
            "\n",
            "0: 640x640 1 person, 1 car, 1 boat, 15.0ms\n",
            "Speed: 7.3ms preprocess, 15.0ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.561\n",
            "Detected class car with confidence 0.476\n",
            "Detected class boat with confidence 0.460\n",
            "-----\n",
            "Processing frames_0042.jpg (42/192)\n",
            "\n",
            "0: 640x640 1 car, 1 boat, 15.0ms\n",
            "Speed: 7.9ms preprocess, 15.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class car with confidence 0.773\n",
            "Detected class boat with confidence 0.446\n",
            "-----\n",
            "Processing frames_0043.jpg (43/192)\n",
            "\n",
            "0: 640x640 1 person, 1 car, 1 boat, 15.0ms\n",
            "Speed: 5.6ms preprocess, 15.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class car with confidence 0.756\n",
            "Detected class person with confidence 0.643\n",
            "Detected class boat with confidence 0.427\n",
            "-----\n",
            "Processing frames_0044.jpg (44/192)\n",
            "\n",
            "0: 640x640 1 person, 1 car, 1 boat, 15.0ms\n",
            "Speed: 5.7ms preprocess, 15.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class car with confidence 0.611\n",
            "Detected class person with confidence 0.459\n",
            "Detected class boat with confidence 0.324\n",
            "-----\n",
            "Processing frames_0045.jpg (45/192)\n",
            "\n",
            "0: 640x640 1 person, 1 car, 15.0ms\n",
            "Speed: 5.5ms preprocess, 15.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class car with confidence 0.662\n",
            "Detected class person with confidence 0.338\n",
            "-----\n",
            "Processing frames_0046.jpg (46/192)\n",
            "\n",
            "0: 640x640 1 car, 15.0ms\n",
            "Speed: 5.5ms preprocess, 15.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class car with confidence 0.661\n",
            "-----\n",
            "Processing frames_0047.jpg (47/192)\n",
            "\n",
            "0: 640x640 1 car, 1 boat, 14.9ms\n",
            "Speed: 5.4ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class car with confidence 0.682\n",
            "Detected class boat with confidence 0.251\n",
            "-----\n",
            "Processing frames_0048.jpg (48/192)\n",
            "\n",
            "0: 640x640 (no detections), 15.0ms\n",
            "Speed: 5.3ms preprocess, 15.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0049.jpg (49/192)\n",
            "\n",
            "0: 640x640 (no detections), 15.0ms\n",
            "Speed: 9.4ms preprocess, 15.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0050.jpg (50/192)\n",
            "\n",
            "0: 640x640 1 boat, 14.9ms\n",
            "Speed: 5.2ms preprocess, 14.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class boat with confidence 0.323\n",
            "-----\n",
            "Processing frames_0051.jpg (51/192)\n",
            "\n",
            "0: 640x640 1 boat, 15.0ms\n",
            "Speed: 7.0ms preprocess, 15.0ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class boat with confidence 0.349\n",
            "-----\n",
            "Processing frames_0052.jpg (52/192)\n",
            "\n",
            "0: 640x640 2 boats, 15.0ms\n",
            "Speed: 5.6ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class boat with confidence 0.371\n",
            "Detected class boat with confidence 0.370\n",
            "-----\n",
            "Processing frames_0053.jpg (53/192)\n",
            "\n",
            "0: 640x640 1 person, 2 boats, 14.9ms\n",
            "Speed: 5.5ms preprocess, 14.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.430\n",
            "Detected class boat with confidence 0.359\n",
            "Detected class boat with confidence 0.312\n",
            "-----\n",
            "Processing frames_0054.jpg (54/192)\n",
            "\n",
            "0: 640x640 1 person, 2 boats, 14.9ms\n",
            "Speed: 5.0ms preprocess, 14.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.625\n",
            "Detected class boat with confidence 0.369\n",
            "Detected class boat with confidence 0.268\n",
            "-----\n",
            "Processing frames_0055.jpg (55/192)\n",
            "\n",
            "0: 640x640 1 person, 1 boat, 14.9ms\n",
            "Speed: 5.4ms preprocess, 14.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class boat with confidence 0.430\n",
            "Detected class person with confidence 0.276\n",
            "-----\n",
            "Processing frames_0056.jpg (56/192)\n",
            "\n",
            "0: 640x640 1 person, 1 boat, 14.9ms\n",
            "Speed: 5.1ms preprocess, 14.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class boat with confidence 0.393\n",
            "Detected class person with confidence 0.267\n",
            "-----\n",
            "Processing frames_0057.jpg (57/192)\n",
            "\n",
            "0: 640x640 1 boat, 14.9ms\n",
            "Speed: 5.3ms preprocess, 14.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class boat with confidence 0.357\n",
            "-----\n",
            "Processing frames_0058.jpg (58/192)\n",
            "\n",
            "0: 640x640 1 boat, 14.9ms\n",
            "Speed: 5.4ms preprocess, 14.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class boat with confidence 0.274\n",
            "-----\n",
            "Processing frames_0059.jpg (59/192)\n",
            "\n",
            "0: 640x640 1 boat, 15.0ms\n",
            "Speed: 5.3ms preprocess, 15.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class boat with confidence 0.317\n",
            "-----\n",
            "Processing frames_0060.jpg (60/192)\n",
            "\n",
            "0: 640x640 1 boat, 14.9ms\n",
            "Speed: 6.1ms preprocess, 14.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class boat with confidence 0.338\n",
            "-----\n",
            "Processing frames_0061.jpg (61/192)\n",
            "\n",
            "0: 640x640 1 boat, 14.9ms\n",
            "Speed: 5.6ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class boat with confidence 0.320\n",
            "-----\n",
            "Processing frames_0062.jpg (62/192)\n",
            "\n",
            "0: 640x640 1 person, 1 boat, 14.9ms\n",
            "Speed: 6.5ms preprocess, 14.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.329\n",
            "Detected class boat with confidence 0.314\n",
            "-----\n",
            "Processing frames_0063.jpg (63/192)\n",
            "\n",
            "0: 640x640 1 boat, 15.0ms\n",
            "Speed: 5.3ms preprocess, 15.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class boat with confidence 0.324\n",
            "-----\n",
            "Processing frames_0064.jpg (64/192)\n",
            "\n",
            "0: 640x640 1 person, 1 boat, 15.0ms\n",
            "Speed: 6.5ms preprocess, 15.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.576\n",
            "Detected class boat with confidence 0.347\n",
            "-----\n",
            "Processing frames_0065.jpg (65/192)\n",
            "\n",
            "0: 640x640 1 person, 1 boat, 15.0ms\n",
            "Speed: 7.2ms preprocess, 15.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.474\n",
            "Detected class boat with confidence 0.351\n",
            "-----\n",
            "Processing frames_0066.jpg (66/192)\n",
            "\n",
            "0: 640x640 1 boat, 14.9ms\n",
            "Speed: 6.6ms preprocess, 14.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class boat with confidence 0.320\n",
            "-----\n",
            "Processing frames_0067.jpg (67/192)\n",
            "\n",
            "0: 640x640 1 person, 1 boat, 14.9ms\n",
            "Speed: 7.1ms preprocess, 14.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.387\n",
            "Detected class boat with confidence 0.312\n",
            "-----\n",
            "Processing frames_0068.jpg (68/192)\n",
            "\n",
            "0: 640x640 1 person, 1 boat, 1 dog, 14.9ms\n",
            "Speed: 5.3ms preprocess, 14.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.733\n",
            "Detected class boat with confidence 0.353\n",
            "Detected class dog with confidence 0.289\n",
            "-----\n",
            "Processing frames_0069.jpg (69/192)\n",
            "\n",
            "0: 640x640 1 person, 1 boat, 1 dog, 14.9ms\n",
            "Speed: 5.6ms preprocess, 14.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.767\n",
            "Detected class boat with confidence 0.381\n",
            "Detected class dog with confidence 0.288\n",
            "-----\n",
            "Processing frames_0070.jpg (70/192)\n",
            "\n",
            "0: 640x640 1 person, 1 boat, 1 dog, 14.9ms\n",
            "Speed: 5.2ms preprocess, 14.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.754\n",
            "Detected class boat with confidence 0.372\n",
            "Detected class dog with confidence 0.347\n",
            "-----\n",
            "Processing frames_0071.jpg (71/192)\n",
            "\n",
            "0: 640x640 1 person, 1 boat, 1 dog, 15.0ms\n",
            "Speed: 5.5ms preprocess, 15.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.777\n",
            "Detected class dog with confidence 0.401\n",
            "Detected class boat with confidence 0.386\n",
            "-----\n",
            "Processing frames_0072.jpg (72/192)\n",
            "\n",
            "0: 640x640 1 person, 1 boat, 1 dog, 15.0ms\n",
            "Speed: 5.4ms preprocess, 15.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.781\n",
            "Detected class boat with confidence 0.389\n",
            "Detected class dog with confidence 0.350\n",
            "-----\n",
            "Processing frames_0073.jpg (73/192)\n",
            "\n",
            "0: 640x640 1 person, 1 boat, 1 dog, 15.0ms\n",
            "Speed: 5.5ms preprocess, 15.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.784\n",
            "Detected class boat with confidence 0.384\n",
            "Detected class dog with confidence 0.292\n",
            "-----\n",
            "Processing frames_0074.jpg (74/192)\n",
            "\n",
            "0: 640x640 1 person, 1 boat, 1 dog, 14.9ms\n",
            "Speed: 5.4ms preprocess, 14.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.779\n",
            "Detected class boat with confidence 0.393\n",
            "Detected class dog with confidence 0.358\n",
            "-----\n",
            "Processing frames_0075.jpg (75/192)\n",
            "\n",
            "0: 640x640 1 person, 1 boat, 1 dog, 14.9ms\n",
            "Speed: 5.6ms preprocess, 14.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.774\n",
            "Detected class boat with confidence 0.382\n",
            "Detected class dog with confidence 0.350\n",
            "-----\n",
            "Processing frames_0076.jpg (76/192)\n",
            "\n",
            "0: 640x640 1 person, 1 boat, 1 dog, 16.9ms\n",
            "Speed: 7.2ms preprocess, 16.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.757\n",
            "Detected class dog with confidence 0.418\n",
            "Detected class boat with confidence 0.406\n",
            "-----\n",
            "Processing frames_0077.jpg (77/192)\n",
            "\n",
            "0: 640x640 1 person, 1 boat, 1 dog, 15.0ms\n",
            "Speed: 5.4ms preprocess, 15.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.774\n",
            "Detected class dog with confidence 0.382\n",
            "Detected class boat with confidence 0.309\n",
            "-----\n",
            "Processing frames_0078.jpg (78/192)\n",
            "\n",
            "0: 640x640 1 person, 1 boat, 1 dog, 14.9ms\n",
            "Speed: 5.4ms preprocess, 14.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.713\n",
            "Detected class dog with confidence 0.385\n",
            "Detected class boat with confidence 0.363\n",
            "-----\n",
            "Processing frames_0079.jpg (79/192)\n",
            "\n",
            "0: 640x640 1 person, 1 boat, 14.9ms\n",
            "Speed: 5.3ms preprocess, 14.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.682\n",
            "Detected class boat with confidence 0.371\n",
            "-----\n",
            "Processing frames_0080.jpg (80/192)\n",
            "\n",
            "0: 640x640 1 person, 1 boat, 14.9ms\n",
            "Speed: 5.5ms preprocess, 14.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.738\n",
            "Detected class boat with confidence 0.441\n",
            "-----\n",
            "Processing frames_0081.jpg (81/192)\n",
            "\n",
            "0: 640x640 1 person, 1 boat, 14.9ms\n",
            "Speed: 5.4ms preprocess, 14.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.781\n",
            "Detected class boat with confidence 0.353\n",
            "-----\n",
            "Processing frames_0082.jpg (82/192)\n",
            "\n",
            "0: 640x640 1 person, 1 boat, 15.0ms\n",
            "Speed: 5.1ms preprocess, 15.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.461\n",
            "Detected class boat with confidence 0.374\n",
            "-----\n",
            "Processing frames_0083.jpg (83/192)\n",
            "\n",
            "0: 640x640 1 person, 1 boat, 15.0ms\n",
            "Speed: 5.2ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.772\n",
            "Detected class boat with confidence 0.413\n",
            "-----\n",
            "Processing frames_0084.jpg (84/192)\n",
            "\n",
            "0: 640x640 1 boat, 14.9ms\n",
            "Speed: 6.1ms preprocess, 14.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class boat with confidence 0.342\n",
            "-----\n",
            "Processing frames_0085.jpg (85/192)\n",
            "\n",
            "0: 640x640 1 person, 1 boat, 15.0ms\n",
            "Speed: 6.3ms preprocess, 15.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.427\n",
            "Detected class boat with confidence 0.385\n",
            "-----\n",
            "Processing frames_0086.jpg (86/192)\n",
            "\n",
            "0: 640x640 1 person, 1 boat, 15.0ms\n",
            "Speed: 5.2ms preprocess, 15.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.753\n",
            "Detected class boat with confidence 0.449\n",
            "-----\n",
            "Processing frames_0087.jpg (87/192)\n",
            "\n",
            "0: 640x640 1 person, 1 boat, 14.9ms\n",
            "Speed: 5.3ms preprocess, 14.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.794\n",
            "Detected class boat with confidence 0.440\n",
            "-----\n",
            "Processing frames_0088.jpg (88/192)\n",
            "\n",
            "0: 640x640 1 person, 1 boat, 1 dog, 15.0ms\n",
            "Speed: 5.6ms preprocess, 15.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.683\n",
            "Detected class boat with confidence 0.597\n",
            "Detected class dog with confidence 0.526\n",
            "-----\n",
            "Processing frames_0089.jpg (89/192)\n",
            "\n",
            "0: 640x640 2 persons, 1 boat, 14.9ms\n",
            "Speed: 5.4ms preprocess, 14.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class boat with confidence 0.488\n",
            "Detected class person with confidence 0.417\n",
            "Detected class person with confidence 0.322\n",
            "-----\n",
            "Processing frames_0090.jpg (90/192)\n",
            "\n",
            "0: 640x640 1 person, 1 boat, 15.0ms\n",
            "Speed: 5.7ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class boat with confidence 0.388\n",
            "Detected class person with confidence 0.339\n",
            "-----\n",
            "Processing frames_0091.jpg (91/192)\n",
            "\n",
            "0: 640x640 1 person, 1 boat, 15.0ms\n",
            "Speed: 6.5ms preprocess, 15.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.565\n",
            "Detected class boat with confidence 0.265\n",
            "-----\n",
            "Processing frames_0092.jpg (92/192)\n",
            "\n",
            "0: 640x640 (no detections), 15.0ms\n",
            "Speed: 6.2ms preprocess, 15.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0093.jpg (93/192)\n",
            "\n",
            "0: 640x640 (no detections), 14.9ms\n",
            "Speed: 5.6ms preprocess, 14.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0094.jpg (94/192)\n",
            "\n",
            "0: 640x640 1 boat, 15.0ms\n",
            "Speed: 6.4ms preprocess, 15.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class boat with confidence 0.291\n",
            "-----\n",
            "Processing frames_0095.jpg (95/192)\n",
            "\n",
            "0: 640x640 (no detections), 15.0ms\n",
            "Speed: 5.7ms preprocess, 15.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0096.jpg (96/192)\n",
            "\n",
            "0: 640x640 (no detections), 14.9ms\n",
            "Speed: 5.4ms preprocess, 14.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0097.jpg (97/192)\n",
            "\n",
            "0: 640x640 (no detections), 14.9ms\n",
            "Speed: 5.6ms preprocess, 14.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0098.jpg (98/192)\n",
            "\n",
            "0: 640x640 (no detections), 15.0ms\n",
            "Speed: 6.5ms preprocess, 15.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0099.jpg (99/192)\n",
            "\n",
            "0: 640x640 (no detections), 15.0ms\n",
            "Speed: 5.7ms preprocess, 15.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0100.jpg (100/192)\n",
            "\n",
            "0: 640x640 1 person, 1 boat, 14.9ms\n",
            "Speed: 5.5ms preprocess, 14.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.599\n",
            "Detected class boat with confidence 0.330\n",
            "-----\n",
            "Processing frames_0101.jpg (101/192)\n",
            "\n",
            "0: 640x640 1 person, 15.0ms\n",
            "Speed: 8.6ms preprocess, 15.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.515\n",
            "-----\n",
            "Processing frames_0102.jpg (102/192)\n",
            "\n",
            "0: 640x640 1 person, 14.9ms\n",
            "Speed: 5.5ms preprocess, 14.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.355\n",
            "-----\n",
            "Processing frames_0103.jpg (103/192)\n",
            "\n",
            "0: 640x640 (no detections), 14.9ms\n",
            "Speed: 5.6ms preprocess, 14.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0104.jpg (104/192)\n",
            "\n",
            "0: 640x640 1 person, 15.0ms\n",
            "Speed: 6.2ms preprocess, 15.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.341\n",
            "-----\n",
            "Processing frames_0105.jpg (105/192)\n",
            "\n",
            "0: 640x640 1 person, 15.0ms\n",
            "Speed: 5.8ms preprocess, 15.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.654\n",
            "-----\n",
            "Processing frames_0106.jpg (106/192)\n",
            "\n",
            "0: 640x640 1 person, 14.9ms\n",
            "Speed: 5.8ms preprocess, 14.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.481\n",
            "-----\n",
            "Processing frames_0107.jpg (107/192)\n",
            "\n",
            "0: 640x640 1 person, 15.0ms\n",
            "Speed: 5.4ms preprocess, 15.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.505\n",
            "-----\n",
            "Processing frames_0108.jpg (108/192)\n",
            "\n",
            "0: 640x640 (no detections), 15.0ms\n",
            "Speed: 8.0ms preprocess, 15.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0109.jpg (109/192)\n",
            "\n",
            "0: 640x640 (no detections), 15.0ms\n",
            "Speed: 5.7ms preprocess, 15.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0110.jpg (110/192)\n",
            "\n",
            "0: 640x640 (no detections), 14.9ms\n",
            "Speed: 5.8ms preprocess, 14.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0111.jpg (111/192)\n",
            "\n",
            "0: 640x640 (no detections), 15.0ms\n",
            "Speed: 5.8ms preprocess, 15.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0112.jpg (112/192)\n",
            "\n",
            "0: 640x640 1 person, 1 car, 15.0ms\n",
            "Speed: 6.0ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.452\n",
            "Detected class car with confidence 0.361\n",
            "-----\n",
            "Processing frames_0113.jpg (113/192)\n",
            "\n",
            "0: 640x640 (no detections), 15.0ms\n",
            "Speed: 5.8ms preprocess, 15.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0114.jpg (114/192)\n",
            "\n",
            "0: 640x640 1 car, 15.0ms\n",
            "Speed: 6.1ms preprocess, 15.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class car with confidence 0.554\n",
            "-----\n",
            "Processing frames_0115.jpg (115/192)\n",
            "\n",
            "0: 640x640 1 car, 14.9ms\n",
            "Speed: 5.6ms preprocess, 14.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class car with confidence 0.558\n",
            "-----\n",
            "Processing frames_0116.jpg (116/192)\n",
            "\n",
            "0: 640x640 1 car, 15.0ms\n",
            "Speed: 5.8ms preprocess, 15.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class car with confidence 0.771\n",
            "-----\n",
            "Processing frames_0117.jpg (117/192)\n",
            "\n",
            "0: 640x640 1 car, 15.0ms\n",
            "Speed: 6.5ms preprocess, 15.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class car with confidence 0.784\n",
            "-----\n",
            "Processing frames_0118.jpg (118/192)\n",
            "\n",
            "0: 640x640 1 car, 1 boat, 14.9ms\n",
            "Speed: 5.5ms preprocess, 14.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class car with confidence 0.526\n",
            "Detected class boat with confidence 0.298\n",
            "-----\n",
            "Processing frames_0119.jpg (119/192)\n",
            "\n",
            "0: 640x640 1 person, 1 truck, 1 boat, 14.9ms\n",
            "Speed: 5.6ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.756\n",
            "Detected class truck with confidence 0.454\n",
            "Detected class boat with confidence 0.319\n",
            "-----\n",
            "Processing frames_0120.jpg (120/192)\n",
            "\n",
            "0: 640x640 1 person, 1 truck, 14.9ms\n",
            "Speed: 5.7ms preprocess, 14.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.291\n",
            "Detected class truck with confidence 0.254\n",
            "-----\n",
            "Processing frames_0121.jpg (121/192)\n",
            "\n",
            "0: 640x640 1 car, 14.9ms\n",
            "Speed: 5.5ms preprocess, 14.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class car with confidence 0.743\n",
            "-----\n",
            "Processing frames_0122.jpg (122/192)\n",
            "\n",
            "0: 640x640 1 person, 1 car, 15.0ms\n",
            "Speed: 5.5ms preprocess, 15.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class car with confidence 0.782\n",
            "Detected class person with confidence 0.382\n",
            "-----\n",
            "Processing frames_0123.jpg (123/192)\n",
            "\n",
            "0: 640x640 1 person, 1 car, 14.9ms\n",
            "Speed: 5.5ms preprocess, 14.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class car with confidence 0.816\n",
            "Detected class person with confidence 0.599\n",
            "-----\n",
            "Processing frames_0124.jpg (124/192)\n",
            "\n",
            "0: 640x640 1 person, 1 car, 15.0ms\n",
            "Speed: 5.7ms preprocess, 15.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class car with confidence 0.723\n",
            "Detected class person with confidence 0.436\n",
            "-----\n",
            "Processing frames_0125.jpg (125/192)\n",
            "\n",
            "0: 640x640 2 persons, 1 car, 14.9ms\n",
            "Speed: 5.6ms preprocess, 14.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class car with confidence 0.791\n",
            "Detected class person with confidence 0.546\n",
            "Detected class person with confidence 0.399\n",
            "-----\n",
            "Processing frames_0126.jpg (126/192)\n",
            "\n",
            "0: 640x640 1 person, 1 car, 15.0ms\n",
            "Speed: 7.6ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class car with confidence 0.630\n",
            "Detected class person with confidence 0.597\n",
            "-----\n",
            "Processing frames_0127.jpg (127/192)\n",
            "\n",
            "0: 640x640 1 person, 14.9ms\n",
            "Speed: 5.6ms preprocess, 14.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.848\n",
            "-----\n",
            "Processing frames_0128.jpg (128/192)\n",
            "\n",
            "0: 640x640 1 person, 14.9ms\n",
            "Speed: 5.6ms preprocess, 14.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.812\n",
            "-----\n",
            "Processing frames_0129.jpg (129/192)\n",
            "\n",
            "0: 640x640 1 person, 1 dog, 14.9ms\n",
            "Speed: 5.5ms preprocess, 14.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.761\n",
            "Detected class dog with confidence 0.274\n",
            "-----\n",
            "Processing frames_0130.jpg (130/192)\n",
            "\n",
            "0: 640x640 1 person, 14.9ms\n",
            "Speed: 5.8ms preprocess, 14.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.802\n",
            "-----\n",
            "Processing frames_0131.jpg (131/192)\n",
            "\n",
            "0: 640x640 1 person, 14.9ms\n",
            "Speed: 5.6ms preprocess, 14.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.683\n",
            "-----\n",
            "Processing frames_0132.jpg (132/192)\n",
            "\n",
            "0: 640x640 1 person, 15.0ms\n",
            "Speed: 5.7ms preprocess, 15.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.787\n",
            "-----\n",
            "Processing frames_0133.jpg (133/192)\n",
            "\n",
            "0: 640x640 1 person, 14.9ms\n",
            "Speed: 5.6ms preprocess, 14.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.836\n",
            "-----\n",
            "Processing frames_0134.jpg (134/192)\n",
            "\n",
            "0: 640x640 1 person, 14.9ms\n",
            "Speed: 5.6ms preprocess, 14.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.823\n",
            "-----\n",
            "Processing frames_0135.jpg (135/192)\n",
            "\n",
            "0: 640x640 1 person, 14.9ms\n",
            "Speed: 6.2ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.752\n",
            "-----\n",
            "Processing frames_0136.jpg (136/192)\n",
            "\n",
            "0: 640x640 1 person, 15.0ms\n",
            "Speed: 6.5ms preprocess, 15.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.827\n",
            "-----\n",
            "Processing frames_0137.jpg (137/192)\n",
            "\n",
            "0: 640x640 1 person, 15.0ms\n",
            "Speed: 5.7ms preprocess, 15.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.820\n",
            "-----\n",
            "Processing frames_0138.jpg (138/192)\n",
            "\n",
            "0: 640x640 1 person, 14.9ms\n",
            "Speed: 5.6ms preprocess, 14.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.797\n",
            "-----\n",
            "Processing frames_0139.jpg (139/192)\n",
            "\n",
            "0: 640x640 1 person, 15.0ms\n",
            "Speed: 6.6ms preprocess, 15.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.839\n",
            "-----\n",
            "Processing frames_0140.jpg (140/192)\n",
            "\n",
            "0: 640x640 1 person, 15.0ms\n",
            "Speed: 5.5ms preprocess, 15.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.834\n",
            "-----\n",
            "Processing frames_0141.jpg (141/192)\n",
            "\n",
            "0: 640x640 1 person, 15.1ms\n",
            "Speed: 6.8ms preprocess, 15.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.738\n",
            "-----\n",
            "Processing frames_0142.jpg (142/192)\n",
            "\n",
            "0: 640x640 1 person, 1 boat, 1 handbag, 14.9ms\n",
            "Speed: 5.7ms preprocess, 14.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.828\n",
            "Detected class boat with confidence 0.533\n",
            "Detected class handbag with confidence 0.297\n",
            "-----\n",
            "Processing frames_0143.jpg (143/192)\n",
            "\n",
            "0: 640x640 1 person, 1 boat, 15.0ms\n",
            "Speed: 6.5ms preprocess, 15.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.755\n",
            "Detected class boat with confidence 0.408\n",
            "-----\n",
            "Processing frames_0144.jpg (144/192)\n",
            "\n",
            "0: 640x640 1 person, 1 boat, 15.0ms\n",
            "Speed: 5.8ms preprocess, 15.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.727\n",
            "Detected class boat with confidence 0.436\n",
            "-----\n",
            "Processing frames_0145.jpg (145/192)\n",
            "\n",
            "0: 640x640 1 person, 14.9ms\n",
            "Speed: 5.9ms preprocess, 14.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.601\n",
            "-----\n",
            "Processing frames_0146.jpg (146/192)\n",
            "\n",
            "0: 640x640 1 person, 14.9ms\n",
            "Speed: 5.6ms preprocess, 14.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.405\n",
            "-----\n",
            "Processing frames_0147.jpg (147/192)\n",
            "\n",
            "0: 640x640 1 person, 14.9ms\n",
            "Speed: 5.7ms preprocess, 14.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.756\n",
            "-----\n",
            "Processing frames_0148.jpg (148/192)\n",
            "\n",
            "0: 640x640 1 person, 15.0ms\n",
            "Speed: 6.3ms preprocess, 15.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.810\n",
            "-----\n",
            "Processing frames_0149.jpg (149/192)\n",
            "\n",
            "0: 640x640 1 person, 14.9ms\n",
            "Speed: 5.9ms preprocess, 14.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.775\n",
            "-----\n",
            "Processing frames_0150.jpg (150/192)\n",
            "\n",
            "0: 640x640 1 person, 14.9ms\n",
            "Speed: 5.8ms preprocess, 14.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.683\n",
            "-----\n",
            "Processing frames_0199.jpg (151/192)\n",
            "\n",
            "0: 640x640 (no detections), 15.0ms\n",
            "Speed: 5.3ms preprocess, 15.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0200.jpg (152/192)\n",
            "\n",
            "0: 640x640 (no detections), 15.0ms\n",
            "Speed: 7.5ms preprocess, 15.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0201.jpg (153/192)\n",
            "\n",
            "0: 640x640 (no detections), 15.0ms\n",
            "Speed: 11.0ms preprocess, 15.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0202.jpg (154/192)\n",
            "\n",
            "0: 640x640 (no detections), 15.0ms\n",
            "Speed: 5.6ms preprocess, 15.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0203.jpg (155/192)\n",
            "\n",
            "0: 640x640 (no detections), 15.0ms\n",
            "Speed: 6.7ms preprocess, 15.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0204.jpg (156/192)\n",
            "\n",
            "0: 640x640 (no detections), 14.9ms\n",
            "Speed: 5.6ms preprocess, 14.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0205.jpg (157/192)\n",
            "\n",
            "0: 640x640 (no detections), 15.0ms\n",
            "Speed: 5.6ms preprocess, 15.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0206.jpg (158/192)\n",
            "\n",
            "0: 640x640 (no detections), 14.9ms\n",
            "Speed: 5.7ms preprocess, 14.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0207.jpg (159/192)\n",
            "\n",
            "0: 640x640 (no detections), 14.9ms\n",
            "Speed: 5.6ms preprocess, 14.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0208.jpg (160/192)\n",
            "\n",
            "0: 640x640 (no detections), 15.0ms\n",
            "Speed: 5.6ms preprocess, 15.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0209.jpg (161/192)\n",
            "\n",
            "0: 640x640 (no detections), 14.9ms\n",
            "Speed: 5.6ms preprocess, 14.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0210.jpg (162/192)\n",
            "\n",
            "0: 640x640 (no detections), 15.0ms\n",
            "Speed: 6.0ms preprocess, 15.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0211.jpg (163/192)\n",
            "\n",
            "0: 640x640 (no detections), 15.0ms\n",
            "Speed: 10.0ms preprocess, 15.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0212.jpg (164/192)\n",
            "\n",
            "0: 640x640 (no detections), 15.0ms\n",
            "Speed: 7.6ms preprocess, 15.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0213.jpg (165/192)\n",
            "\n",
            "0: 640x640 (no detections), 15.0ms\n",
            "Speed: 6.9ms preprocess, 15.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0214.jpg (166/192)\n",
            "\n",
            "0: 640x640 (no detections), 15.0ms\n",
            "Speed: 9.8ms preprocess, 15.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0215.jpg (167/192)\n",
            "\n",
            "0: 640x640 (no detections), 19.1ms\n",
            "Speed: 10.7ms preprocess, 19.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0216.jpg (168/192)\n",
            "\n",
            "0: 640x640 (no detections), 14.9ms\n",
            "Speed: 5.8ms preprocess, 14.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections\n",
            "-----\n",
            "Processing frames_0217.jpg (169/192)\n",
            "\n",
            "0: 640x640 1 person, 14.9ms\n",
            "Speed: 5.7ms preprocess, 14.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.771\n",
            "-----\n",
            "Processing frames_0218.jpg (170/192)\n",
            "\n",
            "0: 640x640 1 person, 15.0ms\n",
            "Speed: 5.8ms preprocess, 15.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.804\n",
            "-----\n",
            "Processing frames_0219.jpg (171/192)\n",
            "\n",
            "0: 640x640 1 person, 15.0ms\n",
            "Speed: 6.5ms preprocess, 15.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.746\n",
            "-----\n",
            "Processing frames_0220.jpg (172/192)\n",
            "\n",
            "0: 640x640 1 person, 14.9ms\n",
            "Speed: 5.9ms preprocess, 14.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.792\n",
            "-----\n",
            "Processing frames_0221.jpg (173/192)\n",
            "\n",
            "0: 640x640 1 person, 15.0ms\n",
            "Speed: 5.9ms preprocess, 15.0ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.803\n",
            "-----\n",
            "Processing frames_0222.jpg (174/192)\n",
            "\n",
            "0: 640x640 1 person, 15.0ms\n",
            "Speed: 6.3ms preprocess, 15.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.541\n",
            "-----\n",
            "Processing frames_0223.jpg (175/192)\n",
            "\n",
            "0: 640x640 1 person, 15.0ms\n",
            "Speed: 7.7ms preprocess, 15.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.628\n",
            "-----\n",
            "Processing frames_0224.jpg (176/192)\n",
            "\n",
            "0: 640x640 1 person, 14.9ms\n",
            "Speed: 7.1ms preprocess, 14.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.538\n",
            "-----\n",
            "Processing frames_0225.jpg (177/192)\n",
            "\n",
            "0: 640x640 1 person, 15.0ms\n",
            "Speed: 7.0ms preprocess, 15.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.643\n",
            "-----\n",
            "Processing frames_0226.jpg (178/192)\n",
            "\n",
            "0: 640x640 1 person, 1 dog, 14.9ms\n",
            "Speed: 5.8ms preprocess, 14.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.773\n",
            "Detected class dog with confidence 0.339\n",
            "-----\n",
            "Processing frames_0227.jpg (179/192)\n",
            "\n",
            "0: 640x640 1 person, 14.9ms\n",
            "Speed: 6.7ms preprocess, 14.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.814\n",
            "-----\n",
            "Processing frames_0228.jpg (180/192)\n",
            "\n",
            "0: 640x640 1 person, 14.9ms\n",
            "Speed: 5.8ms preprocess, 14.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.782\n",
            "-----\n",
            "Processing frames_0229.jpg (181/192)\n",
            "\n",
            "0: 640x640 1 person, 14.9ms\n",
            "Speed: 6.6ms preprocess, 14.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.836\n",
            "-----\n",
            "Processing frames_0230.jpg (182/192)\n",
            "\n",
            "0: 640x640 1 person, 15.0ms\n",
            "Speed: 5.8ms preprocess, 15.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.564\n",
            "-----\n",
            "Processing frames_0231.jpg (183/192)\n",
            "\n",
            "0: 640x640 1 person, 15.0ms\n",
            "Speed: 6.5ms preprocess, 15.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.833\n",
            "-----\n",
            "Processing frames_0232.jpg (184/192)\n",
            "\n",
            "0: 640x640 2 persons, 15.0ms\n",
            "Speed: 6.5ms preprocess, 15.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.429\n",
            "Detected class person with confidence 0.357\n",
            "-----\n",
            "Processing frames_0233.jpg (185/192)\n",
            "\n",
            "0: 640x640 1 person, 15.0ms\n",
            "Speed: 5.5ms preprocess, 15.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.661\n",
            "-----\n",
            "Processing frames_0234.jpg (186/192)\n",
            "\n",
            "0: 640x640 1 person, 15.0ms\n",
            "Speed: 5.9ms preprocess, 15.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.824\n",
            "-----\n",
            "Processing frames_0235.jpg (187/192)\n",
            "\n",
            "0: 640x640 2 persons, 15.0ms\n",
            "Speed: 5.8ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.709\n",
            "Detected class person with confidence 0.250\n",
            "-----\n",
            "Processing frames_0236.jpg (188/192)\n",
            "\n",
            "0: 640x640 1 person, 15.0ms\n",
            "Speed: 5.9ms preprocess, 15.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.853\n",
            "-----\n",
            "Processing frames_0237.jpg (189/192)\n",
            "\n",
            "0: 640x640 1 person, 15.0ms\n",
            "Speed: 6.0ms preprocess, 15.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.855\n",
            "-----\n",
            "Processing frames_0238.jpg (190/192)\n",
            "\n",
            "0: 640x640 1 person, 14.9ms\n",
            "Speed: 6.0ms preprocess, 14.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.874\n",
            "-----\n",
            "Processing frames_0239.jpg (191/192)\n",
            "\n",
            "0: 640x640 2 persons, 1 boat, 14.9ms\n",
            "Speed: 5.9ms preprocess, 14.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.864\n",
            "Detected class person with confidence 0.373\n",
            "Detected class boat with confidence 0.257\n",
            "-----\n",
            "Processing frames_0240.jpg (192/192)\n",
            "\n",
            "0: 640x640 1 person, 15.0ms\n",
            "Speed: 6.8ms preprocess, 15.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detected class person with confidence 0.827\n",
            "-----\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# i am forever humbled and grateful to geoff hinton for sharing his glom and forward forward paper with all of us.\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import glob\n",
        "from pathlib import Path\n",
        "import cv2\n",
        "from einops import rearrange, reduce, repeat\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "from model import Model\n",
        "import clip\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((448, 448)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "]) # these are standard mean and standard deviation values for RGB values from large image datasets\n",
        "\n",
        "\n",
        "class ModelTTA(nn.Module):\n",
        "    def __init__(self, hidden_dim = 1024, h = 32, w = 32, fwd_chunk_size = 16, num_classes= 10, backbone_path = None):\n",
        "\n",
        "        super(ModelTTA, self).__init__()\n",
        "\n",
        "        device = 'cuda'\n",
        "        #load the clip model\n",
        "        self.clip_teacher, self.preprocess = clip.load('ViT-L/14', device)\n",
        "\n",
        "\n",
        "        print(\"init model\")\n",
        "        self.backbone = Model(hidden_dim = hidden_dim, h = h, w = w, fwd_chunk_size = fwd_chunk_size) #backbone is an instance of \"Model\"\n",
        "        print(\"loaded backbone\")\n",
        "        print(\"loaded classification\")\n",
        "        self.h = h\n",
        "        self.w = w\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, img,cls_id, image_features):#, x, x_avg, feat): #image_features and cls_id are the feature vector\n",
        "        x = transform(img)\n",
        "        # print(\"x is\", x.shape)\n",
        "        x = repeat(x, 'c h w -> b c h w', b = 8) #prepare for forward passes.\n",
        "        x_avg = F.avg_pool2d(x, kernel_size=(14,14), stride=(14,14))\n",
        "\n",
        "\n",
        "        #forward pass through backbone, and force it to align\n",
        "        loss, feat_loss, rgb_loss, feat_out, rgb_out,orig_feat_out = self.backbone.forward_wrapper(x, x_avg, image_features) #image features of clip are target for our model\n",
        "\n",
        "        return loss, feat_out,orig_feat_out\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    # print(\"testing dataset\", clip.available_models())\n",
        "    # exit(1)\n",
        "    from torchvision.datasets import CIFAR100\n",
        "    import os\n",
        "    dataset = CIFAR100(root=os.path.expanduser(\"~/data\"), download=True, train=False)\n",
        "    model = ModelTTA().cuda()\n",
        "    for idx in range(len(dataset)):\n",
        "\n",
        "        print(\"doing\", idx+1, \"of\", len(dataset))\n",
        "        image, class_id = dataset[idx]\n",
        "        loss, status = model(image,class_id, dataset,)\n",
        "        # print(\"image is\", image.shape)\n",
        "        print(\"loss is\", loss,status)\n",
        "        # exit(1)\n",
        "    # x = torch.randn(4,3,448,448)\n",
        "    # x_avg = torch.randn(4,3,32,32)\n",
        "    # feat = torch.randn(4,1024)\n",
        "    # model(x,x_avg, feat)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "obvAF2mptJfa",
        "outputId": "5fe6a22b-0163-4e85-f19f-95be7b857a89"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'clip'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-2178018041>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'clip'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## train_tta.py\n",
        "\n",
        "I modified this code to use YOLO instead of CLIP."
      ],
      "metadata": {
        "id": "5w1bEV1Gavmr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import glob\n",
        "from pathlib import Path\n",
        "import cv2\n",
        "from einops import rearrange, reduce, repeat\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import math\n",
        "from torchvision import transforms\n",
        "import torchvision\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# NEW: Import YOLOv5\n",
        "from ultralytics import YOLO\n",
        "model = YOLO(\"yolo11n.pt\")\n",
        "\n",
        "scaler = GradScaler()\n",
        "\n",
        "# Hyperparameters\n",
        "h, w = 32, 32\n",
        "d = 1024\n",
        "n_iters_tta = 1200\n",
        "n_samples_fwd = 4\n",
        "patch_size = 14\n",
        "fwd_chunk_size = 512\n",
        "batch_size = 32 * 2\n",
        "num_workers = 8\n",
        "num_epochs = 15\n",
        "lr = 1e-4\n",
        "device = 'cuda'\n",
        "train_print_freq = 50\n",
        "is_train = False\n",
        "target_trues = 1200\n",
        "\n",
        "# Load YOLOv5 model (download yolov5s.pt if needed)\n",
        "model = YOLO(\"yolo11n.pt\")\n",
        "\n",
        "def randomize_weights_student(model):\n",
        "    for param in model.parameters():\n",
        "        print(\"randomizing!!!\")\n",
        "        nn.init.normal_(param.data, mean=0, std=0.01)\n",
        "\n",
        "model_tta = ModelTTA(hidden_dim=1024, h=32, w=32, fwd_chunk_size=16, num_classes=2, backbone_path=None).cuda()\n",
        "\n",
        "# Use CIFAR10 for now, modify later if needed\n",
        "dataset = torchvision.datasets.CIFAR10(root='~/data', train=is_train, download=True, transform=None)\n",
        "\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "\n",
        "optimizer = torch.optim.Adam(model_tta.parameters(), lr=lr)\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=200, gamma=0.1)\n",
        "\n",
        "correct, n_preds = 0, 0\n",
        "\n",
        "def dump_island(orig_feat_out, i, iter):\n",
        "    orig_feat_out = orig_feat_out.detach().cpu().numpy()\n",
        "    orig_feat_out = orig_feat_out[0]\n",
        "    feat_out = rearrange(orig_feat_out, 'h w d -> (h w) d')\n",
        "    feat = TSNE(n_components=1, learning_rate='auto',\n",
        "                init='random', perplexity=3).fit_transform(feat_out)\n",
        "    feat = (feat - np.min(feat)) / (np.max(feat) - np.min(feat))\n",
        "    feat = feat.squeeze(-1)\n",
        "    feat = rearrange(feat, '(h w)  -> h w ', h=32, w=32)\n",
        "\n",
        "    feat = repeat(feat, 'h w -> h w c', c=3)\n",
        "    feat = feat * 255\n",
        "    feat = feat.astype(np.uint8)\n",
        "    feat = np.concatenate([orig_img, feat], axis=1)\n",
        "    save_str = '{}_{}.png'.format(i, iter)\n",
        "    cv2.imwrite(save_str, feat)\n",
        "    print(\"write done\")\n",
        "\n",
        "idx = 200\n",
        "for i in range(idx, len(dataset)):\n",
        "    print(\"discarded backbone and reloaded weights from scratch\")\n",
        "    randomize_weights_student(model_tta.backbone)\n",
        "    print(\"randomized\")\n",
        "    n_trues = 0\n",
        "    is_last_True = False\n",
        "\n",
        "    img, label = dataset[i]\n",
        "    orig_img = np.array(img)\n",
        "\n",
        "    # Convert to BGR for OpenCV compatibility\n",
        "    img_bgr = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    # Run YOLO inference\n",
        "    results = yolo.predict(img_bgr)\n",
        "\n",
        "    # Check if any detection is 'person' (class 0 in COCO)\n",
        "    contains_person = any(int(cls) == 0 for cls in results.pred[0][:, 5])\n",
        "\n",
        "    # Create binary label based on YOLO detection\n",
        "    yolo_label = 1 if contains_person else 0\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    was_correctly_predicted = False\n",
        "    break_count = 0\n",
        "\n",
        "    for iter in range(n_iters_tta):\n",
        "        print(\"iter\", iter, '/', n_iters_tta)\n",
        "\n",
        "        with autocast():\n",
        "            # Forward TTA model\n",
        "            loss, feat_out, orig_feat_out = model_tta(img, yolo_label)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            scheduler.step()\n",
        "            print(\"loss scaled\", loss)\n",
        "\n",
        "        if iter % 50 == 0:\n",
        "            print(\"going for routing\")\n",
        "            dump_island(orig_feat_out, i, iter)\n",
        "\n",
        "    break  # REMOVE this break to run full loop\n"
      ],
      "metadata": {
        "id": "AmZxO9XsazmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chat output for classifying person vs no person"
      ],
      "metadata": {
        "id": "mF50j_cym6Tc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class TokenRegressor(nn.Module):\n",
        "    def __init__(self, input_dim=3*224*224, token_dim=256):  # Match YOLO token size\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(input_dim, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, token_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# Loss: L2 between predicted and true YOLO person token\n",
        "mse_loss = nn.MSELoss()\n",
        "\n",
        "def train_model(model, train_loader, optimizer, epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for images, true_tokens in tqdm(train_loader):\n",
        "            images, true_tokens = images.to(device), true_tokens.to(device)\n",
        "            pred_tokens = model(images)\n",
        "\n",
        "            loss = mse_loss(pred_tokens, true_tokens)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}: Avg Train Loss = {total_loss / len(train_loader):.4f}\")\n"
      ],
      "metadata": {
        "id": "KaSynotgm4Ez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is the original train_tta file:"
      ],
      "metadata": {
        "id": "nCmpyC4yOl23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import glob\n",
        "from pathlib import Path\n",
        "import cv2\n",
        "from einops import rearrange, reduce, repeat\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import math\n",
        "from torchvision import transforms\n",
        "import torchvision\n",
        "from model_tta import ModelTTA\n",
        "import clip\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "scaler = GradScaler()\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "\n",
        "h,w = 32,32\n",
        "d = 1024\n",
        "n_iters_tta = 1200 #number of iterations for test time training for each sample\n",
        "n_samples_fwd = 4\n",
        "patch_size = 14\n",
        "fwd_chunk_size = 512\n",
        "batch_size = 32*2\n",
        "num_workers = 8\n",
        "num_epochs = 15\n",
        "lr = 1e-4\n",
        "device = 'cuda'\n",
        "train_print_freq = 50\n",
        "is_train = False\n",
        "target_trues = 1200\n",
        "\n",
        "clip_teacher, preprocess = clip.load('ViT-L/14', device)\n",
        "\n",
        "def randomize_weights_student(model):\n",
        "    for param in model.parameters():\n",
        "        print(\"randomizing!!!\")\n",
        "        nn.init.normal_(param.data, mean=0, std=0.01)  # Initialize with random values from a normal distribution\n",
        "\n",
        "\n",
        "model_tta = ModelTTA(hidden_dim = 1024, h = 32, w = 32, fwd_chunk_size = 16, num_classes= 10, backbone_path = None).cuda()\n",
        "dataset = torchvision.datasets.CIFAR10(root = '~/data', train=is_train, download=True, transform=None)\n",
        "\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "\n",
        "optimizer = torch.optim.Adam(model_tta.parameters(), lr=lr)\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=200, gamma=0.1)\n",
        "\n",
        "correct,n_preds =0,0\n",
        "\n",
        "\n",
        "\n",
        "def dump_island(orig_feat_out, i, iter):\n",
        "    orig_feat_out = orig_feat_out.detach().cpu().numpy()\n",
        "    orig_feat_out = orig_feat_out[0]\n",
        "    feat_out = rearrange(orig_feat_out, 'h w d -> (h w) d')\n",
        "    feat = TSNE(n_components=1, learning_rate='auto',\n",
        "                 init='random', perplexity=3).fit_transform(feat_out)\n",
        "    feat = (feat - np.min(feat)) / (np.max(feat) - np.min(feat))\n",
        "    feat = feat.squeeze(-1)\n",
        "    feat = rearrange(feat, '(h w)  -> h w ', h = 32, w = 32)\n",
        "\n",
        "    feat = repeat(feat, 'h w -> h w c', c = 3)\n",
        "    feat = feat * 255\n",
        "    feat = feat.astype(np.uint8)\n",
        "    feat = np.concatenate([orig_img, feat], axis = 1)\n",
        "    save_str = '{}_{}.png'.format(i, iter)\n",
        "    cv2.imwrite(save_str, feat)\n",
        "    print(\"write done\")\n",
        "idx = 200\n",
        "for i in range(idx, len(dataset)):\n",
        "    # adapt the model everytime\n",
        "    print(\"discarded backbone and reloaded weights from scratch\")\n",
        "    randomize_weights_student(model_tta.backbone)\n",
        "    print(\"randomized\")\n",
        "    n_trues=0\n",
        "    is_last_True = False\n",
        "    # exit(1)\n",
        "    img, label = dataset[i]\n",
        "    orig_img = np.array(img)\n",
        "\n",
        "    # print(\"image shape\", orig_img.shape)\n",
        "    # exit(1)\n",
        "    optimizer.zero_grad()\n",
        "    was_correctly_predicted = False\n",
        "    break_count =0\n",
        "    for iter in range(n_iters_tta):\n",
        "\n",
        "        print(\"iter\", iter, '/', n_iters_tta)\n",
        "        image_input = preprocess(img).unsqueeze(0).to('cuda')\n",
        "        text_inputs = torch.cat([clip.tokenize(f\"a photo of a {c}\") for c in dataset.classes]).to('cuda')\n",
        "        with autocast():\n",
        "            with torch.no_grad():\n",
        "                image_features = clip_teacher.encode_image(image_input)\n",
        "                text_features = clip_teacher.encode_text(text_inputs)\n",
        "\n",
        "\n",
        "            image_features = repeat(image_features, 'b d-> b b1 d', b1 = 8)\n",
        "            image_features = rearrange(image_features, 'b b1 d -> (b b1) d')\n",
        "\n",
        "        # with autocast():\n",
        "            loss, feat_out,orig_feat_out = model_tta(img, label, image_features) #forward pass with the one image img, the label/image features output from teacher model,\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            scheduler.step()\n",
        "            # loss.backward()\n",
        "            # optimizer.step()\n",
        "            print(\"loss scaled\", loss)\n",
        "\n",
        "            image_features = feat_out[0]\n",
        "            # text_features = text_features.to(torch.float32)\n",
        "            # image_features = image_features.to(torch.float32)\n",
        "            image_features = image_features.unsqueeze(0)\n",
        "\n",
        "            # print(\"image features\", image_features.shape, text_features.shape, image_features.dtype, text_features.dtype)\n",
        "            image_features /= image_features.norm(dim=-1, keepdim=True)\n",
        "            text_features /= text_features.norm(dim=-1, keepdim=True)\n",
        "            similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
        "            values, indices = similarity[0].topk(5)\n",
        "            index = indices[0]\n",
        "\n",
        "\n",
        "        if iter%50==0:\n",
        "            print(\"going for routing\")\n",
        "            dump_island(orig_feat_out, i, iter)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Cu8o3vdAOqeJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualizations"
      ],
      "metadata": {
        "id": "Udq05StptkLG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize output of model_tta.py"
      ],
      "metadata": {
        "id": "hYH9oCkntm-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "from torchvision import transforms\n",
        "from ultralytics import YOLO\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Path to your image folder\n",
        "folder_path = '/content/APM-David-Copy/lawnmower_images/lawnmower_images/train'\n",
        "\n",
        "# Load YOLO model\n",
        "model = YOLO('yolov5s.pt')\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model.to(device)\n",
        "\n",
        "# Define transformation (optional resize)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((640, 640)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Select 10 random images\n",
        "image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "random.shuffle(image_files)\n",
        "selected_images = image_files[:9]\n",
        "\n",
        "# Set up the grid\n",
        "fig, axes = plt.subplots(3, 3, figsize=(20, 8))\n",
        "\n",
        "for i, img_name in enumerate(selected_images):\n",
        "    img_path = os.path.join(folder_path, img_name)\n",
        "    img_pil = Image.open(img_path).convert(\"RGB\")\n",
        "    img_np = np.array(img_pil)\n",
        "\n",
        "    # Run inference\n",
        "    results = model(img_np)\n",
        "\n",
        "    # Determine if 'person' is detected\n",
        "    found_person = False\n",
        "    for res in results:\n",
        "        boxes = res.boxes\n",
        "        if boxes is not None and len(boxes) > 0:\n",
        "            for box in boxes:\n",
        "                cls_id = int(box.cls[0])\n",
        "                class_name = model.model.names[cls_id]\n",
        "                if class_name.lower() == 'person':\n",
        "                    found_person = True\n",
        "                    break\n",
        "        if found_person:\n",
        "            break\n",
        "\n",
        "    label = \"Person\" if found_person else \"No Person\"\n",
        "\n",
        "    # Plot\n",
        "    ax = axes[i //3, i % 3]\n",
        "    ax.imshow(img_pil)\n",
        "    ax.set_title(label, fontsize=14, color='green' if found_person else 'red')\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "4hG0WzpptxIt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}