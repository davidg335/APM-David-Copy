# Asynchronous Perception Machine For Efficient Test Time Training 

Our proposed Asynchronous Perception Machine represents a new way to do machine perception: i.e. asynchronous perception. This involves processing patches of an image one at a time in any order, and still encode semantic awareness in the network. This helps us in moving towards architectures which consume less flops and occupy less on-device-memory, and predict almost same features that a transformer predicts. This also allows us to achieve strong performance on test-time-training benchmarks. 

This is the public official release of our model, and we urge researchers across the world to try some more of GLOM's ideas in their labs. We will add more code here as we make progress. 

